Job ID,Description
0,"At Applied Materials, we are building the next generation fab productivity solutions using Artificial Intelligence and Machine Learning. Our AI/ML team is looking for a Data Scientist who will be responsible for building predictive and prescriptive models to increase and optimize fab productivity. The data scientist must be self-directed and independent in conducting their work as well as working with and supporting globally distributed teams. The right candidate will be excited by the prospect of building our company’s next generation data science practice and products.
Responsibilities

Formulate and lead guided, multifaceted analytic studies against large volumes of data.
Interpret and analyze data using exploratory mathematic and statistical techniques based on the scientific method.
Coordinate research and analytic activities utilizing various data points (unstructured and structured) and employ programming to clean, massage, and organize the data.
Experiment against data points, provide information based on experiment results and provide previously undiscovered solutions to command data challenges.
Develop, productize and maintain machine learning and optimization models according to requirements to transform our product into an innovative industry leader
Analyze problems and determines root causes.
Work with stakeholders including the Product management, Data and Design teams to build models.
Support our customers with their data science and optimization problems using our product
Qualifications

Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.
Experience working with ‘big data’ data pipelines, architectures and data sets.
Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.
Strong analytic skills related to working with unstructured datasets.
A successful history of manipulating, processing and extracting value from large disconnected datasets.
Strong project management and organizational skills.
Experience supporting and working with cross-functional teams in a dynamic environment.
Experience with big data tools: Hadoop, Spark, Kafka, etc.
Experience with relational SQL and NoSQL databases, including Postgres, Cassandra, MongoDB.
Experience with cloud AI services from AWS, Google, Azure
Experience with optimization tools: Gurobi, CPLEX, etc.
Experience with object-oriented/object function scripting languages: Python, Java, C++, Scala, etc.
Education/Experience

Candidate with 2+ years of experience in a Data Scientist role, who has attained a Graduate degree in Operations Research, Computer Science, Statistics, Informatics, Information Systems or another quantitative field"
1,"We, from Vestibulum Technologies, located at Bangalore, are inviting applications from minimum 6 months experienced professionals for the below mentioned skills


We follow SDLC / CI CD practices to develop custom curated solutions for mobile desktop web and data science machine learning deep learning domain


This post is not for Testing Engineers, SSE, Product Managers and those in the top cadre


We build Software Solutions / AI Solutions for our own in-house Dev Firm


We do not provide Training


We do not take bond no service agreement and we compensate you based on your performance / output / problem solving capabilities


We have openings for the below mentioned skills


, Machine Learning ( Supervised Learning, Unsupervised Learning, Reinforcement Learning )


, Deep Learning, Computer Vision, NLP


You should have done projects based on TensorFlow, TensorFlow Serving, TFX


PyTorch, PyTorch Lightning, Torchaudio, Torchvideo, Torchelastic


knowledge of AutoML, pycaret, Sagemaker is a advantage but not mandatory


Please do let us know when are you available for a intense 30 mins to 1 hour technical discussion / programming test interview for the above skills at google meet

This is a 2 months paid internship and FTE (*)


Do forward your resume to

careers.vest@vestibulum.net

venkatasrini2021@gmail.com , with this screenshot

(*)- subject to your performance during the Internship


Thanks for reading the post"
2,"Machine Learning Engineers opening with a leading AI Organization based out of U.S.A with Work from anywhere opportunity.


Job Title : Machine Learning Engineer, Full time position

Experience : 2 to 3 years

Qualification : Graduation in any Stream/Discipline.

Key skills : Python, Pandas and Numpy.

Location : Remote / Work from anywhere

Pay range : Competitive as per market depending upon skill sets possessed by the candidate.

Selected candidate will have the opportunity to work in Data science projects with Fortune 500 companies and eminent professors from Global universities.

Candidates meeting the above eligibility criteria may send in your cv's to chidambaram@flipped.ai or Whatsapp your profile to +91-96775-26679"
3,"Greetings from Skillvertex

Please read the details carefully before applying..

In this Internship and Training, you'll learn all about becoming proficient in selected domain, from the responsibilities that a MNC experts performs on a day-to-day basis to the set of skills that you'd need to succeed in such a role. And, of course, you'll also get your hands dirty with code: We'll introduce you to the fundamental building blocks of Industry qualified.

1st Month: Industrial Training

The first month is for training in which the students will be taught by top MNC experts in their Domain of interest via live/ recorded lectures. The training will cover the basics in the domain such that students with no prior experience may also be able to learn effectively.

2nd Month: Industrial Projects

The second month features two project opportunities for the students to implement the knowledge they have acquired. The first is a minor or individual project for 7 days which is to encourage every student to bring into practice what they have learned and the second is a major or group project in which the students will be working in teams of 5-10 members to simulate an office work environment similar to that in MNCs. The students would have access to the study material for a total period of 6 months as well as intellectual property rights to the completed projects.

After Completion of Two month. You will be certified with three
certificate.
🎓 Training Completion Certificate
🎓 Internship Completion Certificate
🎓 Excellence Performance Certificate

The entire program is supervised by industry experts from our affiliated MNCs who will be guiding the students through their projects with the help of a planned curriculum as well as their personal experiences.


PLEASE NOTE: THERE WILL BE A TRAINING FEE."
4,"We are Picsniff - our mission is to change the lives of millions of photographers worldwide. We are doing this by automating mundane tasks using machine learning. Our founder, Anand Rathi, was named in the 'Top 100 photographers of the world' in 2019 and is a computer engineer from IIIT Hyderabad.


Our current product has received tremendous traction but we are just getting started . To achieve our vision we are looking at senoir Computer vision engineers.


Minimum qualifications:

3+ years of professional, hands-on computer vision experience with the ability to translate research into applications

Primary responsibilities would include:

Developing on a state-of-the-art system to help accomplish the product vision
Expand the team

What’s in it for you:


Competitive compensation
Generous perks and benefits
100% remote work

If this has got you thinking, ping the founder Anand Rathi at anand@picsniff.com or on his LinkedIn profile."
5,"Profile: SQL Developer

Job Description:

Create or modify SQL scripts or stored procedures
Perform database insertions via SQL script or stored procedure
Manipulate data to meet import requirements while maintaining data integrity
Follow standard practices and procedures and apply basic theories, concepts, principles and methodologies in analyzing situations or data
Troubleshoot and resolve system issues
Compose project documentation (e.g., high level use cases, detailed business specifications) and translate business needs into technical requirements
Follow and support corporate security policies, standards, and procedures as they apply to this role. Maintain customer and corporate standards as outlined by HIPAA.
Pay range unavailable
Salary information is not available at the moment."
6,"Job Description


Hiring Interns at Rabbani ITI college for various role.

1. Human Resources Intern

The duration of internship is available in 6 month's only.

Applicants must be MBA(HR) completed or pursuing
Perks :
1. Appointment Letter
2. Internship Completion Certificate
3. Letter of Appreciation
4. Letter of Recommendations

Due to Pandemic and lockdown restrictions. This is going to be virtual internship program Candidate are supposed to work from their h"
7,"Qualification: Graduate/PG
Background: Computer Science/IT Preferred
Experience: Freshers are also eligible

Skills: Knowledge of HTML,CSS, Blockly
Programming Language Skillset (HTML, CSS, Js, React Native, Python) preferred

Location: PAN India
Notice Period: Immediate Joiner

Interview Mode: Virtual
Shift: As per the School Timing
Salary: Upto 3L INR"
8,"Profile: Python Developer

The services enable our corporate and institutional clients to access financial markets and liquidity, unlock investment opportunities, manage risk and transact seamlessly. Our global network is combined with emerging markets leadership and specialist expertise, giving clients the confidence to go where the growth is and capture new opportunities. The application or API s that they are trying to build here is connecting with the multiple source systems (File share, share point, Jira, API uses, Database). Gathering the data from various sources and then managing the data and finding the risk and control and the presenting the data to the team. It s like exposing the data via API.

What will you get to learn?

Experience of working with infrastructure teams to deliver the best architecture for applications.
Working in a global team with different cultures.
Knowledge or experience with Development pipelines and automation in a CI/CD context.
Broad experience with IT development and collaboration tools (Git/Bit bucket; Confluence; Jira; etc.).
IT Security and Application Development best practice.
IT industry process knowledge in some or all of ITIL; Agile/Scrum; DevOps principles.
Can learn qlikview, cognos, data stage, Grafana.
Resource would not be restricted to one project but would have to the opportunity to contribute and deliver within the timelines to the multiple areas of Automation and Robotics. Freehand to come up with new technologies and ideas on how they could contribute. The organization has fearless work culture where they will get a chance to work free hand under a fearless culture.
Google Cloud Platform
Team is known for Single click deployments and 1200 releases
Candidates will get to solve complex business challenges and sensitive systems and will get a chance to work on large data size.
Candidates will get a chance to work on agile and DevOPs environment.

Skills Required (Mandatory):

Python Development
Uses and Development of API or Micro services
Knowledge of Database"
9,"Designation - Data Scientist

Urgently required. (NP of maximum 15 days)

Location:- Mumbai

Experience:- 3-7 years.

Package Offered:- Rs.3,00,000/- to Rs.7,00,000/- pa.


Data Scientist


Job Description:-

Responsibilities:

Identify valuable data sources and automate collection processes
Undertake preprocessing of structured and unstructured data
Analyze large amounts of information to discover trends and patterns
Build predictive models and machine-learning algorithms
Combine models through ensemble modeling
Present information using data visualization techniques
Propose solutions and strategies to business challenges
Collaborate with engineering and product development teams
Requirements:

Proven experience as a Data Scientist or Data Analyst
Experience in data mining
Understanding of machine-learning and operations research
Knowledge of R, SQL and Python; familiarity with Scala, Java is an asset
Experience using business intelligence tools (e.g. Tableau) and data frameworks (e.g. Hadoop)
Analytical mind and business acumen
Strong math skills (e.g. statistics, algebra)
Problem-solving aptitude
Excellent communication and presentation skills
BSc/BA in Computer Science, Engineering or relevant field; graduate degree in Data Science or other quantitative field is preferred"
10,"About the job
Greeting from SKILLVERTEX

www.skillvertex.in


It gives me immense pleasure to introduce ourselves as one of the top leading and emerging edtech platforms in India with our head office in Bangalore.


We offer project based training, Internship and placement assistance programs for engineering and management students.


Our aim is to provide quality education via real time training and upskill the students so as to make them industry ready.


We offer internship programs which span over a period of two months which include training under industry experts as well as industrial project experience.


-Cloud Computing

-Data Science

-Cyber Security

-Web Development

-Android Development

-Machine Learning

-Artificial Intelligence

-Python

-Finance

-Marketing and Sales

-Stock Market

-Digital Marketing

-Embedded Systems

-Robotics

-Internet of Things- IoT

-Hybrid and Electric Vehicles

-Autocad

-IC Engine design (only recorded)

-Hybrid and Electric Vehicle

-Construction planning


The students may opt for any domain under the respective fields


The internship program is the same for all of these domains.


1st Month : Industrial Training


The first month is for training in which the students will be taught in their selected domains via live/recorded lectures. The training will cover from the basics in all the domains such that students with no prior experience may also be able to learn effectively.


2nd Month : Industrial Projects


The second month features two project opportunities for the students to implement the knowledge they have acquired. The first is a minor or individual project for 7 days which is to encourage every student to bring into practice what they have learnt and the second is a major or group project in which the students will be working in teams of 5-10 members to simulate an office work environment similar to that in MNCs. The students would have access to the study material for a total period of 6 months as well as intellectual property rights to the completed projects..


The entire program is supervised by industry experts from our affiliated MNCs who will be guiding the students through their projects with the help of planned curriculum as well as their personal experiences.


PLEASE NOTE: THERE WILL BE TRAINING FEES."
11,"About the job
Greeting from SKILLVERTEX

www.skillvertex.in


It gives me immense pleasure to introduce ourselves as one of the top leading and emerging edtech platforms in India with our head office in Bangalore.


We offer project based training, Internship and placement assistance programs for engineering and management students.


Our aim is to provide quality education via real time training and upskill the students so as to make them industry ready.


We offer internship programs which span over a period of two months which include training under industry experts as well as industrial project experience.


1st Month : Industrial Training


The first month is for training in which the students will be taught in their selected domains via live/recorded lectures. The training will cover from the basics in all the domains such that students with no prior experience may also be able to learn effectively.


2nd Month : Industrial Projects


The second month features two project opportunities for the students to implement the knowledge they have acquired. The first is a minor or individual project for 7 days which is to encourage every student to bring into practice what they have learnt and the second is a major or group project in which the students will be working in teams of 5-10 members to simulate an office work environment similar to that in MNCs. The students would have access to the study material for a total period of 6 months as well as intellectual property rights to the completed projects..


The entire program is supervised by industry experts from our affiliated MNCs who will be guiding the students through their projects with the help of planned curriculum as well as their personal experiences.


PLEASE NOTE: THERE WILL BE TRAINING FEES.
ONLINE LIVE SESSIONS- 6000₹/-
RECORDED SESSIONS- 4000₹/-"
12,"The ideal candidate will be responsible for creating python microservices.


Job Description

Design, develop, troubleshoot, and debug python microservices.
Work closely with Architects and Senior Developers to achieve effective and optimized code.
Unit test, build, and deploy the services to cloud.
Focus on developing and deploying the programs.

Job Requirements

Min. 1 to 2 years of related experience
Having dominant skills in: Python, Web Development
Having essential skills in: Python Django, HTML, CSS, Javascript, Jquery, Bootstrap
Strong analytical skills
Strong communication skills including the ability to convey technical information effectively
Having good perfomance in completing the tasks within an agreed schedule

About EIS LABS Pvt. Ltd. ®

EIS LABS Pvt. Ltd. ® is a tangible manifestation of the lofty ideals of some visionaries, who are well known experts in their respective fields of work. We had always nurtured a dream & desire to make a significant contribution to the nation through collaboration of education with industry. Our dream and desire inspired us to establish a platform, EIS LABS Pvt. Ltd. ®. The vision for the company is to bring the academic researches on a single platform and mold them into industrial products with the help of our expertise."
13,"The ideal candidate should have strong communication skill

Responsibilities-
Collaborate with the team.
Maintain the internal works
Managing internal assets.

Qualifications-
Bachelor’s degree in HR or related field.
Experience as an HR
Freshers are also welcomed

Strong communication skill, basic computer knowledge
Knowledge about google sheets,Ms.word, google doc etc.

Internship program duration : 6 month
Salary structure: No salary till 6 month

Requirement : Laptop or system with good internet speed
Work from Home

Work timing: 4 Hours (including learning hours)
Notice period: 15 days.

Post Successful compilation of internship programs. Intern will get work experience certificate or internship certificate based on performance."
14,"The ideal candidate will use their passion for big data and analytics to provide insights to the business covering a range of topics. They will be responsible for conducting both recurring and ad hoc analysis for business users.

Responsibilities

Understand the day-to-day issues that our business faces, which can be better understood with data
Compile and analyze data related to business issues
Develop clear visualizations to convey complicated data in a straightforward fashion
We are looking for a curious and collaborative Analyst to solve business problems using data.
As a Data Analyst, you will use analytical, statistical and programming skills to collect, analyze and interpret large datasets.
You are expected to have strong data analytical skills with statistical background and hands-on experience in not only building machine learning models but also deploying them to production.

Qualifications

2+ years of experience in solving business problems using various analytical and statistical techniques.
You think about data in terms of statistical distributions and have a big enough analytics toolbox to know how to find patterns in data and communicate the findings using visualizations
You have experience writing SQL queries to create datasets for analytics and modeling (e.g. SQL, BigQuery, Hive)
Apply statistical analysis and visualization techniques to various data, Generate hypotheses about the underlying mechanics of the business process
Test hypotheses using various quantitative methods
Display drive and curiosity to understand the business process to its core
Network with domain experts to better understand the business mechanics that generated the data
Apply various ML and advanced analytics techniques to perform classification or prediction tasks
Integrate domain knowledge into the ML solution; for example, from an understanding of financial risk, customer journey, quality prediction, sales, marketing
Testing of ML models, such as cross-validation, A/B testing, bias, and fairness
You have proven experience with at least one programming language (e.g. Python, Java, R) and are comfortable developing code in a team environment (e.g. git, notebooks)
Experience in statistical modeling and techniques like GLM, Random Forest, GBM, Neural Networks
You are self-motivated and curious with demonstrated creative and critical thinking capabilities
You have excellent verbal and written communication skills and experience in influencing decisions with information
Your academic background is in a quantitative field such as Computer Science, Statistics, Engineering."
15,"About the job
#python #AI #ML #DL


Summary


Want to own the platform that enables the next generation of intelligent experiences on products and services? Our group develops the platform that is used for developing machine learning, artificial intelligence, and computer vision applications. As a machine learning engineer on our team, you will design and build software systems to enable the future of intelligent products. Join our team of pragmatic, proficient, product-focused engineers!



Key Qualifications


Strong Python programming skills

Understanding of data structures

Software design principles and algorithms

Experience with one or more deep learning frameworks, such as TensorFlow and PyTorch

Hands-on experience developing machine learning solutions

Familiarity with DNN training algorithms.



Description


We're looking for strong machine learning engineers to help build a next-generation framework for training deep learning models. You'll be part of a small team of developers and deep learning experts, working in the area of neural network systems and algorithm optimization. We're looking for candidates with polished coding skills as well as a passion for machine learning and computational science. In exchange, we offer a respectful work environment, flexible responsibilities, and access to world-class experts and growth opportunities—all at one of the best companies in the world. Design and develop components for our centralized, scalable ML platform. Train and evaluate DNNs to push the limits of existing solutions for large-scale training. Develop novel techniques to circumvent the limitations of these solutions and evaluate your techniques on real-world tasks from our partners in Computer Vision. We encourage publishing novel work at top ML conferences.


BONUS QUALIFICATIONS:


Strong background in applied math, including optimization and probability

Strong C++ skills

Publication record at ML conferences

Familiarity with GPU programming.



Education & Experience

4+ Years of Relavent Experience in AI/ Machine Learning / Deep Learning.

Ph.D./MS / B.E. B.Tech (or equivalent in the area of computer science / Electronics / Electrical/ IT)

"
16,"About the job
If you're potential but don't have skills or platform. this could be the best opportunity for you as I’m sponsoring potential candidates in my team for my next project and here are two pay-scale which l can offer
at their initial levels (depending upon their working
capabilities) 25-30k(for part time) & 35-40k (for full
time)
Roll in now
‼️seats are limited‼️"
17,"About the job

We are looking for a data scientist with flair for exploratory data analysis and a problem solving aptitude who will collaborate with stakeholders / cross functional teams to investigate problems, detect patterns and recommend solutions by analysing data.
This is a long-term position for an independent freelancer working 40hrs/week and being paid monthly.

What you’ll be doing:

Collaborate with various stakeholders to understand their problems and goals, make sense of the data landscape, perform a combination of exploratory, Machine Learning & Advanced Analytics.
Make data-driven decisions: design metrics, perform data analysis, collect data in resourceful ways and dive into details to truly understand key customer pain points.
Use strong programming & data science / engineering skills to explore, examine, prepare, and interpret large volumes of data in various forms.
Model complex problems, discover insights and identify opportunities through the use of statistical, algorithmic, mining and visualization techniques.
Distil key insights from data that address the objectives of the analysis, synthesize and clearly communicate findings that focus on the critical issues and provide actionable recommendations to address the business question asked.

What will make you successful:

Bachelor’s degree from an accredited educational institution (preferably in a technical discipline like Computer Science / Electrical Engineering) or with educational background in Statistics / Mathematics or a related quantitative field.
4 - 5 years of relevant work experience in modern data technologies & data science tools and libraries / frameworks.
Hands on experience and expertise in Python, SQL databases, Machine learning / AI, Data visualization, Statistics.
The capacity for self-motivation, independent initiative, creative problem-solving and time management.
Strong analytical and quantitative skills; ability to use hard data and metrics to back up assumptions, recommendations, and drive actions.
Excellent communications skills with respect to translating business needs into a mathematical / data analysis approach and translating analysis results in business terms.
Knowledgeable in Agile software development and DevOps methodologies.
Familiarity with BigQuery / BigData, Cloud computing, Virtual machines, Google cloud platform, NLP, AWS and version control tools like GitHub would be a big plus.
"
18,"Company Description

Merkle is a global data-driven, technology-enabled performance marketing agency. For over 30 years, Fortune 1,000 companies and leading nonprofit organizations have partnered with us to build and maximize the value of their customer portfolios. We work with world-class brands like Dell, T-Mobile, Samsung, GEICO, Regions, Kimberly-Clark, AARP, Lilly, Sanofi, NBC Universal, DIRECTV, American Cancer Society, Habitat for Humanity, and many others to build and execute customer-centric business strategies. With more than 9,000 smart, dedicated people in more than 50 offices around the world, we are still growing at a rate that outpaces the market.

At Merkle, we help brands make the people-based marketing transformation. Using a combination of first- and third-party data, we create, target, and measure the highly customized customer experiences that not only drive immediate results in the form of today’s response and conversion, but also build tomorrow’s increased loyalty and customer value. At the heart of these solutions is Merkle’s deep heritage in the data, analytics, and technology capabilities that enable them.

Our capabilities span people-based marketing disciplines: customer strategy, performance media, customer experience and personalization, customer relationship management, loyalty marketing, and enterprise technology services. This have cross functional teams with a lot of skills and understanding of multiple capabilities, UI/UX, Frontend, Backend, Scalability, Security, Performance, Databases, Caches, Microservices, DevOps, SOA, Integration Patterns, etc.

Merkle is a global data-driven, technology-enabled performance marketing agency. For over 30 years, Fortune 1,000 companies and leading nonprofit organizations have partnered with us to build and maximize the value of their customer portfolios. We work with world-class brands like Dell, T-Mobile, Samsung, GEICO, Regions, Kimberly-Clark, AARP, Lilly, Sanofi, NBC Universal, DIRECTV, American Cancer Society, Habitat for Humanity, and many others to build and execute customer-centric business strategies. With more than 9,000 smart, dedicated people in more than 50 offices around the world, we are still growing at a rate that outpaces the market.

At Merkle, we help brands make the people-based marketing transformation. Using a combination of first- and third-party data, we create, target, and measure the highly customized customer experiences that not only drive immediate results in the form of today’s response and conversion, but also build tomorrow’s increased loyalty and customer value. At the heart of these solutions is Merkle’s deep heritage in the data, analytics, and technology capabilities that enable them.

Our capabilities span people-based marketing disciplines: customer strategy, performance media, customer experience and personalization, customer relationship management, loyalty marketing, and enterprise technology services. This have cross functional teams with a lot of skills and understanding of multiple capabilities, UI/UX, Frontend, Backend, Scalability, Security, Performance, Databases, Caches, Microservices, DevOps, SOA, Integration Patterns, etc.

Job Description

Merkle | Sokrati, a leader in Digital Marketing and Analytics, managing Digital Marketing campaigns for several large brand clients in India. We are currently a 1250+ people team; and growing extremely fast to gain more market share and roll out even cooler technology solutions in Digital Advertising space.

In pursuit of this, we seek to hire an Intern– Data Analytics in our team.

What you’ll do at Merkle|Sokrati?
Use statistical methods to analyze data and generate useful business reports
Analyze client data using EDA and provide actionable insights to improve processes and present them successfully to management using a reporting tool.
Use data to create AI&ML models to solve complex business problems
Provide support for ad hoc requests from the Business Users
Provide support for Analytics Processes monitoring and troubleshooting.
Identify, evaluate and implement external services and tools to support data validation and cleansing
Liaise with internal and external clients to fully understand data content
Gather, understand and document detailed business requirements using appropriate tools and techniques
Support in creating PowerPoints, reports, dashboards and models
Independently determine the appropriate approach for new assignments
Complete a variety of atypical assignments
Solve a range of straight forward problems
Builds knowledge of the organization, processes and customers
What’s On Offer
An opportunity to work with one of India’s most promising companies in a genuine growth hacking role
Unparalleled learning opportunities in the company of ridiculously smart folks with very high levels of expertise in their respective functions
Fantastically transparent, vibrant and positive work culture
Qualifications

What we are looking for?
Someone who is inquisitive and has great problem-solving skills.
Core data science/analytics knwolege.
Hands-on experience of building statistical models like regression, decision tree, random forests and other AI/ML models is a must
Experience using R, Python, SAS is mandatory.
Ability to write SQL queries, doing cohort analysis, comparative analysis etc.
Ability to lead own projects and work independently once given a direction.
Experience working directly with business users to build reports, dashboards and solving business questions with data.
Experience of working on visualization tools (Tableau/Power BI etc.)
Understanding about GA360/Adobe/Datorama/CDP/DMP etc.
Additional Information

Please note: The selected candidates have to start working from office immediately.

At Merkle Sokrati, we don't insist on any paid certification as a part of the hiring process."
19,"As a Data Scientist you will work closely with the Cognitive Wi-Fi team to research and develop techniques for anomaly detection, root cause analysis and auto remediation.


Develop ML models and measure their effectiveness across all of Arista customers
Work on extracting and analysing data from a wide variety of Wi-Fi networks
Develop proof of concepts and ship new features in Arista’s CloudVision Wi-Fi solution.
Possibly share the findings with a larger community through talks and blog posts

Are you right for this role?


This is an interesting and exciting opportunity to be a part of the software team that is redefining Cognitive Wi-Fi.

For success at Arista all you need is:


Strong engineering and Computer Science fundamentals
Minimum two years of experience in Data Science, Machine Learning and AI technologies.
Knowledge of Python or R and SQL.
Knowledge of Pandas (Python) or Tidyverse (R) libraries.
Experience in using Jupyter or RStudio/RMarkdown notebooks"
20,"About the job
MonetizeMore builds industry leading ad technology that is seen by more than 300M people per month. The company has been running for 11 years achieving consistent double digit growth each year with a team of 180+ team members spread across the globe.

MonetizeMore offers location and schedule freedom to every one of its team members. That means that you would have the lifestyle autonomy to choose to work from anywhere in the world, during the time of day you prefer. This new-age work lifestyle would enable you to engineer your ideal lifestyle. Say goodbye to endless commutes, stuffy business attire and the arbitrary 9 – 5 work day. Take your life back into your hands by joining the MonetizeMore team!

The product team is the fastest and most innovative team in the company. Build greenfield technology that is disrupting the ad technology industry. Solve problems that have never been solved before. Join a company culture that replaces constant meetings and interruptions with innovation that continues to break boundaries. Take your skillset to the next level with some of the best minds in the ad technology industry to make a real difference with MonetizeMore.

Job Description

What you will do
Perform exploratory data analysis on auction data to form hypothesis
Build models to test the hypothesis
Optimize auction strategies using statistics and machine learning techniques
Collaborate with other developers to make the models reproducible and production-ready

Who you might be
1-2 years of professional experience in data analysis using Python
Highly knowledgeable in statistics and probability
Experienced in conducting hypothesis testing
Have good understanding of classical machine learning techniques
Knowledgeable in reinforcement learning algorithms is a plus
Proficiency in SQL, pandas, NumPy, scikit-learn, Matplotlib, etc.

Attributes

MonetizeMore attributes include:

Teamwork Attributes
Collaboration: Working remotely on complex projects necessitates that you work together with your team and share knowledge.
Communication Skills: You are comfortable communicating in English at all levels, have strong spoken and written communication skills and are an active listener.
Teamwork: You value team synergy and are excited about helping your team succeed.
Interpersonal Skills: You are able to get along, work well and coordinate with others.
Conflict Management: As a team, we are proactive in dealing with conflict. You are able to find constructive ways of resolving issues with other team members.

Technical Attributes
Technology: A MonetizeMore developer is proficient in all stages of web development, from conception to deployment. You are a one-person army, ready and willing to attack any technical challenge that crosses your path
Analytical and Problem Solving Skills: You work hard to understand technical issues and to resolve them in an effective manner.
Detail Orientation: You work on many parts of an application or system at the same time and are able to focus on each detail meticulously.
Initiative: You work well in a team, with little supervision, making well-reasoned and effective technical decisions.
Reliability and Responsibility: You demonstrate reliability at all times. You give reasonable expectations within the Agile Scrum framework and work hard and smart to achieve and surpass those expectations. You communicate what you are going to do, then meet that commitment.
Thought Leadership: You analyze MonetizeMore’s tech stack, systems and processes with the goal to iterate on a regular basis. You look for opportunities to improve to increase value to MonetizeMore and suggest them to the team.

If you think you are a good fit to join the MonetizeMore Product Team, kindly apply and give specific reasons on what sets you apart. We hire individuals, not robots. Don’t be afraid to show a little personality ;)"
21,"About the job
We are looking for aspirational Data Scientists to solve really complex problems using machine learning and neural nets. If this is you, we’d love to meet you and bring you onboard!

A heads-up on what this role entails:

You will be involved in the complete lifecycle of using machine learning to solve real business problems - including data understanding, feature engineering, model selection, model training, model optimization and deployment.

Experience:


We expect you to have 2+ years of experience in Data Science and machine learning


Hand on real world experience in building & deploying models


Experience working with tensorflow, pyTorch to building LSTM, RNN, GRU models for text, numerical and time series data


Experience working with real world problems and data is required


To be a successful Data Scientist, your skills in math, probability, statistics and building/using algorithms need to be very good!


To be able to express yourself as a Data Scientist, you need to have the ability to to write robust code in Python


Have a bachelor’s degree in computer science, Mathematics or a similar field would be great. A Masters preferred!


Who you are:


We are already liking you if you have the skills listed above. Now to push it over the top, we expect you to have Excellent communication skills; Afterall, you will have to communicate your ideas and your vision with the rest of the team and the management.


We mentioned the team, so being a good team player is important for us."
22,"About the job
MonetizeMore builds industry leading ad technology that is seen by more than 300M people per month. The company has been running for 11 years achieving consistent double digit growth each year with a team of 180+ team members spread across the globe.

MonetizeMore offers location and schedule freedom to every one of its team members. That means that you would have the lifestyle autonomy to choose to work from anywhere in the world, during the time of day you prefer. This new-age work lifestyle would enable you to engineer your ideal lifestyle. Say goodbye to endless commutes, stuffy business attire and the arbitrary 9 – 5 work day. Take your life back into your hands by joining the MonetizeMore team!

The product team is the fastest and most innovative team in the company. Build greenfield technology that is disrupting the ad technology industry. Solve problems that have never been solved before. Join a company culture that replaces constant meetings and interruptions with innovation that continues to break boundaries. Take your skillset to the next level with some of the best minds in the ad technology industry to make a real difference with MonetizeMore.

Job Description

What you will do
Perform exploratory data analysis on auction data to form hypothesis
Build models to test the hypothesis
Optimize auction strategies using statistics and machine learning techniques
Collaborate with other developers to make the models reproducible and production-ready

Who you might be
1-2 years of professional experience in data analysis using Python
Highly knowledgeable in statistics and probability
Experienced in conducting hypothesis testing
Have good understanding of classical machine learning techniques
Knowledgeable in reinforcement learning algorithms is a plus
Proficiency in SQL, pandas, NumPy, scikit-learn, Matplotlib, etc.

Attributes

MonetizeMore attributes include:

Teamwork Attributes
Collaboration: Working remotely on complex projects necessitates that you work together with your team and share knowledge.
Communication Skills: You are comfortable communicating in English at all levels, have strong spoken and written communication skills and are an active listener.
Teamwork: You value team synergy and are excited about helping your team succeed.
Interpersonal Skills: You are able to get along, work well and coordinate with others.
Conflict Management: As a team, we are proactive in dealing with conflict. You are able to find constructive ways of resolving issues with other team members.

Technical Attributes
Technology: A MonetizeMore developer is proficient in all stages of web development, from conception to deployment. You are a one-person army, ready and willing to attack any technical challenge that crosses your path
Analytical and Problem Solving Skills: You work hard to understand technical issues and to resolve them in an effective manner.
Detail Orientation: You work on many parts of an application or system at the same time and are able to focus on each detail meticulously.
Initiative: You work well in a team, with little supervision, making well-reasoned and effective technical decisions.
Reliability and Responsibility: You demonstrate reliability at all times. You give reasonable expectations within the Agile Scrum framework and work hard and smart to achieve and surpass those expectations. You communicate what you are going to do, then meet that commitment.
Thought Leadership: You analyze MonetizeMore’s tech stack, systems and processes with the goal to iterate on a regular basis. You look for opportunities to improve to increase value to MonetizeMore and suggest them to the team.

If you think you are a good fit to join the MonetizeMore Product Team, kindly apply and give specific reasons on what sets you apart. We hire individuals, not robots. Don’t be afraid to show a little personality ;)

Powered by JazzHR

GRq50kVQI5"
23,"About the job
This job is sourced from a job board. Learn more
At Fornax, We empower clients to Optimize | Automate | Structure data collection processes and churn it into valuable insights to drive faster and accurate data-driven decisions.

If you are person who loves cloud services or is quick to learn your way around various cloud services then this is the place to be. Here you would be testing and deploying data analytics solution on cloud.

The role of candidate would be

Create and maintain optimal data pipeline architecture,
Assemble large, complex data sets that meet functional / non-functional business requirements.
Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.
Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL, Python and AWS ‘big data’ Services.
Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.
Work with stakeholders including the Executive, Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs.
Keep our data separated and secure across national boundaries through multiple data centers and AWS regions.
Build and manage Data warehouses. Like Redshift, Big Query, Snowflake etc.
Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.
Work with data and analytics experts to strive for greater functionality in our data systems."
24,"About the job
VALUES THAT DEFINE OUR CULTURE

We are unified by the spirit of going above and beyond for our clients and each other. We look to foster a globally inclusive culture, enabling our people to be themselves at work and to join in, be heard, contribute, and grow. We continually seek to expand our workforce with diverse perspectives, backgrounds, and experiences. We recognize that our best ideas can come from anyone, anywhere, at any time and help us provide the best solutions for our clients around the globe.

Department Description

FactSet is seeking a Data Scientist with trend detection, analysis, and reporting and reporting experience. This role develops and maintains algorithms for document labeling and collection, including human-in-the-loop active learning / machine learning modules for efficient label collection. It also contributes to the development of tools, dashboards, and prototypes for ML/AI systems for trend and performance analysis and reporting.

The role is located within the Content Engineering AI Team and will help inform and deliver the AI roadmap for data quality and product enhancements.Experience with data visualization and NLP is a huge plus, as is experience developing data-driven prototypes. Previous experience in BI or full stack web dev would be helpful but is not required.

Our inclusive work environment maximizes our diversity values, engagement, productivity, and ultimately makes FactSet a fun place to work.

Job Responsibilities
Experience developing data visualization and analytics dashboards
Python data science stack and Jupyter Notebooks (Pandas, Scikit learn, Numpy, etc.)
Data Visualization in Python (Matplotlib, Seaborn, Plotly, ggplot)
Experience designing and tuning time-series metrics
Familiarity with BI / dashboard tools (Superset, Kibana, Grafana, Tableau)
Feature engineering experience
Development of linear models or classifiers for trend or outlier detection and analytics
(Regression, Bayesian classifiers, SVM)
Active learning algorithms
Working with Agile development practices

Job Requirements
Experience developing forms/interfaces to collect document annotations
Widgets and extensions for Jupyter Notebook
Familiarity with Python web stack (Flask or Django)
Ability to work or customize HTML, CSS, or JS
Data science rapid web app frameworks (Streamlit)
Experience with labeling frameworks (AWS Ground Truth, Prodigy, etc.)
Prior experience working with unstructured data (text content, JSON records)
Experience or exposure with AWS environment [SageMaker, S3, Athena, Glue, EC2, EC2]
Prior experience with Docker and API development
Familiarity with NLP, machine learning, deep learning
Experience with Tensorboard or visualization and interpretation of deep learning models
Experience with SpaCy and NLP widgets and visualization
Usage of MongoDB
Exposure to big data tool chain (e.g. Pyspark, Hive)
Experience with R and the RStudio/Shiny tool chain"
25,"About the job
**** Immediate Joiner Preferred ****


Location: Pune/Mumbai


Required Skills:

• Collaborate with Product Management to understand business requirements and design appropriate solutions

• Implementation and enhancement of Data pipelines

• Designs, codes, tests, supports, and documents all new BI systems, applications, reports and visualizations.

• Works with cross-functional teams to ensure the necessary data and analysis environments are available

• Develops the overall data transformation workflows and build appropriate frameworks for continued new product integrations

• Responsible for executing technical user stories for the sprint.

• Enforce and follow technical standards for deliverables of projects.

• Have a very good understanding of Continued integration to drive the DevOps implementation on respective projects using tools - Github, Jenkins.


Roles & Responsibility:

- 3+ year’s professional experience in Big Data Pipelines using Airflow or similar tools

- Proficiency in programming languages like PySpark, Python

- High level of Proficiency in SQL (Advanced) and experience with Semi-structured data

- ETL/Data Processing Technology for Data warehouse/ Data Lakes: Apache Spark, Talend, any other Open source ETL tool.(at least 2 years of experience in any of these tools),

- Knowledge of Real-time Data streaming like Apache Kafka, AWS Kinesis, Spark Streaming

- Must have a high degree of initiative to implement solutions in a fast-paced, dynamic environment.

- Must be able to understand business requirements and translate them into technical deliveries.

- Experience in Large dataset integration with a variety of different sources, each with varying degrees of data quality and cleanliness

- Knowledge and experience of data stores such as SQL Server, PostgreSQL and Cloud datastores like Snowflake - Datawarehouse/ Big data datastores

Desirable:

- Dimensional modeling methodologies and development for data warehouses

- Requires strong analytical, conceptual, and problem-solving abilities

- Familiarity with Agile concepts, and experience practicing SCRUM.

- Experience working with remote teams.

- Must have excellent communication skills.

- Nice to have: Knowledge of Predictive Analytics, ML, Data Mining models

- Nice to have: Knowledge of Data Cataloging"
26,"Our vision is to transform how the world uses information to enrich life for all.

Join an inclusive team passionate about one thing: using their expertise in the relentless pursuit of innovation for customers and partners. The solutions we build help make everything from virtual reality experiences to breakthroughs in neural networks possible. We do it all while committing to integrity, sustainability, and giving back to our communities. Because doing so can fuel the very innovation we are pursuing.

JR9237 DATA ENGINEER, SMAI

Broad Knowledge And Experience In

Understanding of Big Data Engineering/processing, Business Intelligence and Advanced analytics
Developing ETL/ELT processes
Knowledge in databases and Data warehouse modeling
Knowledge in Cloud based data engineering and Machine Learning Models
Knowledge in building APIs for application integration
Experience with various frameworks and processes, such as Agile
Determine transformation requirements and develop processes to bring structured and unstructured data from the source to a new physical Data Model
Work with Data Scientists to implement strategies for cleaning and preparing data for analysis, to develop data imputation algorithms, and optimize performance of big data and machine learning systems

Above Average Skills In

Big Data Engineering and Processing using Hadoop stack (Hadoop, Hive, HDFS, Spark and HBase etc.)
Develop ETL/ELT processing using Apache Ni-Fi
Strong background on SQL and databases
Programming Skills in Python or Scala
Data Analysis and Validation skills

Demonstrated Ability To

Work in a dynamic, fast-paced, work environment
Self-motivated with the ability to work under minimal direction
To adapt to new technologies and learn quickly
A passion for data and information with strong analytical, problem solving, and organizational skills
Work in multi-functional groups, with diverse interests and requirements, to a common objective
Communicate very well with distributed teams (written, verbal and presentation)

About Micron Technology, Inc.

We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience.

To learn more, please visit micron.com/careers

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport_in@micron.com

Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.

Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron."
27,"About the job
Responsible for incident management and receiving incidents and requests from end-users.

Analyze and process these requests by updating the system and responding to the end user

Process, validate and close various regulation compliance (privacy) tickets.

Follow up on the compliance tickets.

Identify and implement practical ideas to improve the existing process.
"
28,"Our vision is to transform how the world uses information to enrich life for all.

Join an inclusive team passionate about one thing: using their expertise in the relentless pursuit of innovation for customers and partners. The solutions we build help make everything from virtual reality experiences to breakthroughs in neural networks possible. We do it all while committing to integrity, sustainability, and giving back to our communities. Because doing so can fuel the very innovation we are pursuing.

JR9233 DATA ENGINEER, SMAI

Broad Knowledge And Experience In

Understanding of Big Data Engineering/processing, Business Intelligence and Advanced analytics
Developing ETL/ELT processes
Knowledge in databases and Data warehouse modeling
Knowledge in Cloud based data engineering and Machine Learning Models
Knowledge in building APIs for application integration
Experience with various frameworks and processes, such as Agile
Determine transformation requirements and develop processes to bring structured and unstructured data from the source to a new physical Data Model
Work with Data Scientists to implement strategies for cleaning and preparing data for analysis, to develop data imputation algorithms, and optimize performance of big data and machine learning systems

Above Average Skills In

Big Data Engineering and Processing using Hadoop stack (Hadoop, Hive, HDFS, Spark and HBase etc.)
Develop ETL/ELT processing using Apache Ni-Fi
Strong background on SQL and databases
Programming Skills in Python or Scala
Data Analysis and Validation skills

Demonstrated Ability To

Work in a dynamic, fast-paced, work environment
Self-motivated with the ability to work under minimal direction
To adapt to new technologies and learn quickly
A passion for data and information with strong analytical, problem solving, and organizational skills
Work in multi-functional groups, with diverse interests and requirements, to a common objective
Communicate very well with distributed teams (written, verbal and presentation)

About Micron Technology, Inc.

We are an industry leader in innovative memory and storage solutions transforming how the world uses information to enrich life for all. With a relentless focus on our customers, technology leadership, and manufacturing and operational excellence, Micron delivers a rich portfolio of high-performance DRAM, NAND, and NOR memory and storage products through our Micron® and Crucial® brands. Every day, the innovations that our people create fuel the data economy, enabling advances in artificial intelligence and 5G applications that unleash opportunities — from the data center to the intelligent edge and across the client and mobile user experience.

To learn more, please visit micron.com/careers

All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.

To request assistance with the application process and/or for reasonable accommodations, please contact hrsupport_in@micron.com

Micron Prohibits the use of child labor and complies with all applicable laws, rules, regulations, and other international and industry labor standards.

Micron does not charge candidates any recruitment fees or unlawfully collect any other payment from candidates as consideration for their employment with Micron.
"
29,"About the job
Job Description

We’re hiring a talented Data Engineer and Big Data enthusiast to work in our platform to help ensure that our data quality is flawless. As a company, we have millions of new data points every day that come into our system. You will be working with a passionate team of engineers to solve challenging problems and ensure that we can deliver the best data to our customers, on-time. You will be using the latest cloud data warehouse technology to build robust and reliable data pipelines.

Duties/Responsibilities Include
Develop expertise in the different upstream data stores and systems across Numerator.
Design, develop and maintain data integration pipelines for Numerators growing data sets and product offerings.
Build testing and QA plans for data pipelines.
Build data validation testing frameworks to ensure high data quality and integrity.
Write and maintain documentation on data pipelines and schemas
Requirements

Skills & Requirements
BS or MS in Computer Science or related field of study
3 + years of experience in the data warehouse space
Expert in SQL, including advanced analytical queries
Proficiency in Python (data structures, algorithms, object oriented programming, using API’s)
Experience working with a cloud data warehouse (Redshift, Snowflake, Vertica)
Experience with a data pipeline scheduling framework (Airflow)
Experience with schema design and data modeling
Exceptional Candidates Will Have
Amazon Web Services (EC2, DMS, RDS) experience
Terraform and/or ansible (or similar) for infrastructure deployment
Airflow -- Experience building and monitoring DAGs, developing custom operators, using script templating solutions.
Experience supporting production systems in an on-call environment"
30,"About the job
Upwork ($UPWK) is the leading tech solution for companies looking to hire the best talent, maintain flexibility, and get more done. We’re passionate about our mission to create economic opportunities so people have better lives. Every year, more than $2 billion of work is done through Upwork by skilled professionals who want the freedom of working anytime, anywhere. Top companies connecting with extraordinary talent around the globe? Upwork is how.

This is a Contract position through Upwork’s Talent Innovation Program (TIP). Our TIP team is a global group of professionals that augment Upwork’s business. Our TIP team members are located all over the world.

Work/Project Scope
This role is with the Upwork Trust and Safety team. The ideal candidate should be a talented and hardworking senior data engineer with expert level knowledge of SQL/PostgreSQL and statistical data analysis approaches.
You will have the opportunity to work on the vast data sets in the Trust and Safety detection area.
You will be working on some business problems that may not have clearly defined requirements and need to be able to do independent research to figure out the details, hypothesize and verify, connect the dots to form the big picture and make recommendations. The ability to think out of the box is desired.
You will work with advanced SQL/Python scripts to slice and dice the existing raw data set, derive the first level data insights on a regular basis, map those out to user life journeys on our platform, project the data trends and estimate the business opportunities proactively.
You will develop and maintain rule based offline reports to continuously monitor the trends and emerging patterns, and to recommend cutoff thresholds which maximize the overall business benefit with a controlled cost.
You will need to respond to ad-hoc business data inquiries but solve them with logical and generalized approaches. Best practices that promote repeatable and predictable successes are highly valued within the team.
You will really impress us if you have good working knowledge with any of the following aspects: data warehouse platforms like Snowflake, OLAP practices, business intelligence tools like Looker/Excel and batch job processing platforms like Rundeck.
You will need to constantly communicate with the business, analytics, data science and engineering counterparts to clarify requirements, derive deep insights into our data, provide feedback, share the discovered data stories via stats, charts and formal presentations, and finally propose recommendations to the business to strengthen our trust and safety defenses on the platform.
This is a long term contract position.
Must Haves (Required Skills/qualifications)
Advanced SQL and statistical data analysis skills to deliver high-quality data queries and reports with good documentation.
Work independently and with minimal supervision.
Communicate frequently and effectively in English.
Be comfortable with multi-tasking and context switches, with proper time management according to business priorities.
Overlap for at least 4 work hours a day on weekdays with the Upwork team located in California.
Besides the above, we also highly value your dedication, sense of ownership, and desire to learn and grow.
Upwork is proudly committed to fostering a diverse and inclusive workforce. We never discriminate based on race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical condition), sexual orientation, gender identity, gender expression, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics."
31,"We are Looking for Data Engineer's for Our Assignment those who can Join within Immediate to 15 Days - Good experience into Hadoop , Kafka, Spark Streaming, Spark, Hive, Spark SQL- Strong Skills in Scala to handle Spark coding.(PySpark not applicable)- Strong experience in data wrangling and analysis.- Good background into DevOps model.- Very good knowledge into stream processing.- Good communication skills.- Independent working capabilities.- Self-Motivated and curiosity to investigate solutions.- Good Team player.- Ability to communicate openly with stake holders and convert the business requirements into functional code meeting the acceptance criteria.- Contribute to solution design and challenge the assumptions by speaking up without fear.- Develop, test and deploy resilient and robust solutions in a timely, high quality and cost-effective way that meet business needs- Deliver resilient and robust operational solutions.- Participate to the deepening maturity of process and practices- Be an active participant across the entire group including attending team ceremonies and technology forums- Contribute to effort estimation, delivery planning.- Experience working in an agile team / team group- Ability to cast a broad net when reaching out for assistance.""- Notice period : Immediate to 15 Days- Position : Fulltime/Permanent (ref:hirist.com)"
32,"Data Engineer ( Associate / Sr. / Lead )Exp : 2 -

7 yrsWork Location : BangaloreJob Description :Activities :- Develop Ingestion framework using Sqoop, Nifi, Kafka, Spark Streaming, WebHDFS, Python to enable seamless data ingestion process on to the Hadoop platform- Exposure of handling structured, Un Structured and Streaming data- Building data processing framework using Talend, Spark, HQL- Enabling Data Governance and Data Discovery on Hadoop Platform- Enabling Security Framework with Kerberos, Ranger, Atlas- Enabling Data Pipeline Automation using DevOps tools- Enable Job Monitoring framework along validations automation- Create Automated testing framework.Roles & Responsibilities :- Understanding the business requirements- Preparing the Design and work on Data Ingestion, Preparation and Transformation.- Develop data streaming applications.- Develop ELT code to move the data to curated zone.- Developing end to end Pipeline automation- Develop the scripts for data sourcing and Parsing scripts using Unix,

Python.- Debugging the production failures and identifying the solution.- Monitor Performance of the Jobs and tuning them as required.- Write extensive Unit and Regression test cases- Create Project Technical DocumentationSkills :Data Engineering: Hadoop, Hive, Sqoop, Hbase, Spark, Nifi, Presto, Kafka, Python, Sql, Unix Scripting, Talend, AtlasWho can join Immediate -

20 days is only preferred. (ref:hirist.com)"
33,"About the job

Do what you love. Love what you do.

At Workday, we help the world’s largest organizations adapt to what’s next by bringing finance, HR, and planning into a single enterprise cloud. We work hard, and we’re serious about what we do. But we like to have fun, too. We put people first, celebrate diversity, drive innovation, and do good in the communities where we live and work.

About the Team
Designs, builds and oversees the deployment and operation of technology architecture, solutions and software to capture, manage, store and utilize structured and unstructured data from internal and external sources. Establishes and builds processes and structures based on business and technical requirements to channel data from multiple inputs, route appropriately and store using any combination of distributed (cloud) structures, local databases, and other applicable storage forms as required. Â Develops technical tools and programming that leverage artificial intelligence, machine learning and big-data techniques to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis. Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements. Reviews internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.
About the Role

Come be a part of something big.

Workday is embarking on our next growth adventure. As our Business Technology team continues its mission to deliver unparalleled value to our business partners and customers, we are expanding our presence in the Asia-Pacific region with a new Business Technology office in Pune, India . This new office will be an essential development center to propel the growth of our company through transformational programs for Go-To-Market and Enterprise Data Analytics teams. If you want to be a part of building something big that will drive value throughout the entire global organization, then this is the opportunity for you. You will be working on top priority initiatives that span new and existing technologies - all to deliver outstanding results and experiences for our Customers and employees.

Our Enterprise Architecture and Data Services team is currently looking for a Data Engineer. The Data Engineer will be an integral member of the Data Services Team in the BT Enterprise Architecture and Data organization. This is a hands-on role which will be responsible for design, development, and implementation of data integration, data warehouse and data mart solutions using cloud technologies. An ideal candidate will have extensive knowledge of the data warehouse and data engineering using latest tools and Open source frameworks.

About the Enterprise Data Services Team:

The Enterprise Data Services organization in Business Technology takes pride in enabling data driven business outcomes to spearhead Workday’s growth through trusted data excellence, innovation and architecture thought leadership. The team is responsible for developing and supporting Data Services, Data Warehouse, Analytics, MDM, Data Quality and Advanced Analytics/ML for multiple business functions including Sales, Marketing, Services, Support and Customer Experience. We leverage leading modern cloud platforms like AWS, Reltio, Tableau, Snaplogic, MongoDB in addition to the native AWS technologies like Spark, Airflow, Redshift, Sagemaker and Kafka

Job Responsibilities:
Develop and automate high-performance data processing systems to drive Workday business growth and improve the product experience.
Evangelize high quality software engineering practices towards building data infrastructure and pipelines at scale.
Build reliable, efficient, testable, & maintainable data pipelines.
Design and Develop data pipelines using Metadata driven ETL Tools and Open source data processing frameworks.
Hands-on experience with source version control, continuous integration and experience with release/change management delivery tools.
Provide production support and resolve high priority incidents and the development coding issues.
Work with cross functional teams to enable data insights through Data lifecycle.

Qualifications:
6+ years of experience designing and building scalable and robust data pipelines to enable data-driven decisions for the business.
Prior experience with CRM systems like SFDC is required.
Experience building analytical solutions to Sales and Marketing teams.
Experience with very large-scale data warehouse and data engineering projects
Experience developing low latency data processing solutions like AWS Kinesis, Kafka, Spark Stream processing.
Should be proficient in writing advanced SQLs, Expertise in performance tuning of SQLs
Experience working with AWS data technologies like S3, EMR, Lambda, DynamoDB, Redshift etc.
Strong experience in one or more programming languages for processing of large data sets, such as Python, Scala.
Ability to create data models, STAR schemas for data consuming.
Extensive experience in troubleshooting data issues, analyzing end to end data pipelines and in working with users in resolving issues
BS/MS in computer science or equivalent is required

About You

NA

Are you being referred to one of our roles? If so, ask your connection at Workday about our Employee Referral process!"
34,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

Be involved in data engineering activities like Creating pipelines / workflows for Source to Target etc.

Responsibilities

You will be involved in the Azure Data platform implementation. Willing to work in shift timings 2PM to 11PM
Responsible for assessing feasibility of migrating customer solutions and/or integrating with 3rd party systems both Microsoft and non-Microsoft platforms
Designing and developing Data Pipelines for Data Ingestion or Transformation using Python (PySpark)/Spark SQL
Work with version control GitHub and CI/CD pipelines using Azure DevOps

If you thrive in a dynamic, collaborative workplace, IBM provides an environment where you will be challenged and inspired every single day. And if you relish the freedom to bring creative, thoughtful solutions to the table, there's no limit to what you can accomplish here.

Required Technical and Professional Expertise

Total Years of Experience 5+ years in IT industry
2+ years current and deep experience with Azure Data platform implementation. Proven experience managing projects through the entire project lifecycle.
Relevant years of experience 2+ years in Azure Data Factory, Azure Data Lake, Azure DevOps, Azure DataBricks, AzureSQL
Proficient in Azure Data Integration, Azure Data Architecture
Proven experience using the Microsoft Azure Data Stack (ADFv2, Azure SQL DB, Azure SQL Datawarehouse, Azure Data Lake, Azure Databricks, Analysis Services, Cosmos DB)
Experience in Azure data migration patterns
Experience in Python, C# is mandatory
Agile methodology experience essential
3+ years’ experience assessing feasibility of migrating customer solutions and/or integrating with 3rd party systems both Microsoft and non-Microsoft platforms
Hands on experience Designing and developing Data Pipelines for Data Ingestion or Transformation using Python (PySpark)/Spark SQL

Preferred Technical And Professional Expertise

AZ 900 - Azure Fundamentals
DP 200, DP 201, DP 203, AZ 204 - Data Engineering
AZ 400 - Devops Certification
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
Experience working with version control GitHub and CI/CD pipelines using Azure DevOps

About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

When applying to jobs of your interest, we recommend that you do so for those that match your experience and expertise. Our recruiters advise that you apply to not more than 3 roles in a year for the best candidate experience.

For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status."
35,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

Be involved in data engineering activities like Creating pipelines / workflows for Source to Target etc.

Responsibilities

You will be involved in the Azure Data platform implementation. Willing to work in shift timings 2PM to 11PM
Responsible for assessing feasibility of migrating customer solutions and/or integrating with 3rd party systems both Microsoft and non-Microsoft platforms
Designing and developing Data Pipelines for Data Ingestion or Transformation using Python (PySpark)/Spark SQL
Work with version control GitHub and CI/CD pipelines using Azure DevOps

If you thrive in a dynamic, collaborative workplace, IBM provides an environment where you will be challenged and inspired every single day. And if you relish the freedom to bring creative, thoughtful solutions to the table, there's no limit to what you can accomplish here.

Required Technical and Professional Expertise

Total Years of Experience 5+ years in IT industry
2+ years current and deep experience with Azure Data platform implementation. Proven experience managing projects through the entire project lifecycle.
Relevant years of experience 2+ years in Azure Data Factory, Azure Data Lake, Azure DevOps, Azure DataBricks, AzureSQL
Proficient in Azure Data Integration, Azure Data Architecture
Proven experience using the Microsoft Azure Data Stack (ADFv2, Azure SQL DB, Azure SQL Datawarehouse, Azure Data Lake, Azure Databricks, Analysis Services, Cosmos DB)
Experience in Azure data migration patterns
Experience in Python, C# is mandatory
Agile methodology experience essential
3+ years’ experience assessing feasibility of migrating customer solutions and/or integrating with 3rd party systems both Microsoft and non-Microsoft platforms
Hands on experience Designing and developing Data Pipelines for Data Ingestion or Transformation using Python (PySpark)/Spark SQL

Preferred Technical And Professional Expertise

AZ 900 - Azure Fundamentals
DP 200, DP 201, DP 203, AZ 204 - Data Engineering
AZ 400 - Devops Certification
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
Experience working with version control GitHub and CI/CD pipelines using Azure DevOps

About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

When applying to jobs of your interest, we recommend that you do so for those that match your experience and expertise. Our recruiters advise that you apply to not more than 3 roles in a year for the best candidate experience.

For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
"
36,"Introduction

At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.

Your Role and Responsibilities

Be involved in data engineering activities like Creating pipelines / workflows for Source to Target etc.

Responsibilities

You will be involved in the Azure Data platform implementation. Willing to work in shift timings 2PM to 11PM
Responsible for assessing feasibility of migrating customer solutions and/or integrating with 3rd party systems both Microsoft and non-Microsoft platforms
Designing and developing Data Pipelines for Data Ingestion or Transformation using Python (PySpark)/Spark SQL
Work with version control GitHub and CI/CD pipelines using Azure DevOps

If you thrive in a dynamic, collaborative workplace, IBM provides an environment where you will be challenged and inspired every single day. And if you relish the freedom to bring creative, thoughtful solutions to the table, there's no limit to what you can accomplish here.

Required Technical and Professional Expertise

Total Years of Experience 5+ years in IT industry
2+ years current and deep experience with Azure Data platform implementation. Proven experience managing projects through the entire project lifecycle.
Relevant years of experience 2+ years in Azure Data Factory, Azure Data Lake, Azure DevOps, Azure DataBricks, AzureSQL
Proficient in Azure Data Integration, Azure Data Architecture
Proven experience using the Microsoft Azure Data Stack (ADFv2, Azure SQL DB, Azure SQL Datawarehouse, Azure Data Lake, Azure Databricks, Analysis Services, Cosmos DB)
Experience in Azure data migration patterns
Experience in Python, C# is mandatory
Agile methodology experience essential
3+ years’ experience assessing feasibility of migrating customer solutions and/or integrating with 3rd party systems both Microsoft and non-Microsoft platforms
Hands on experience Designing and developing Data Pipelines for Data Ingestion or Transformation using Python (PySpark)/Spark SQL

Preferred Technical And Professional Expertise

AZ 900 - Azure Fundamentals
DP 200, DP 201, DP 203, AZ 204 - Data Engineering
AZ 400 - Devops Certification
You love collaborative environments that use agile methodologies to encourage creative design thinking and find innovative ways to develop with cutting edge technologies
Ambitious individual who can work under their own direction towards agreed targets/goals and with creative approach to work
Intuitive individual with an ability to manage change and proven time management
Proven interpersonal skills while contributing to team effort by accomplishing related results as needed
Up-to-date technical knowledge by attending educational workshops, reviewing publications
Experience working with version control GitHub and CI/CD pipelines using Azure DevOps

About Business Unit

IBM Services is a team of business, strategy and technology consultants that design, build, and run foundational systems and services that is the backbone of the world's economy. IBM Services partners with the world's leading companies in over 170 countries to build smarter businesses by reimagining and reinventing through technology, with its outcome-focused methodologies, industry-leading portfolio and world class research and operations expertise leading to results-driven innovation and enduring excellence.

Your Life @ IBM

Are you craving to learn more? Prepared to solve some of the world's most unique challenges? And ready to shape the future for millions of people? If so, then it's time to join us, express your individuality, unleash your curiosity and discover new possibilities.

Every IBMer, and potential ones like yourself, has a voice, carves their own path, and uses their expertise to help co-create and add to our story. Together, we have the power to make meaningful change – to alter the fabric of our clients, of society and IBM itself, to create a truly positive impact and make the world work better for everyone.

It's time to define your career.

About IBM

IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.

Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business.

At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.

Location Statement

When applying to jobs of your interest, we recommend that you do so for those that match your experience and expertise. Our recruiters advise that you apply to not more than 3 roles in a year for the best candidate experience.

For additional information about location requirements, please discuss with the recruiter following submission of your application.

Being You @ IBM

IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, pregnancy, disability, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
"
37,"Because you belong at Twilio

The Who, What, Why And Where

Twilio is growing rapidly and seeking a Data Engineer to be a key member of the Enterprise Data & Business Intelligence organization with the focus on data engineering services based in Bengaluru, India. You will be joining one of the first teams of engineers in our new Bengaluru office and as the early engineers in the Enterprise Data & BI organization in Bengaluru, you will have an opportunity to help define our technical and team culture in India. You will design and build data platforms and services, while handling our data infrastructure in cloud environments that fuels strategic business decisions across Twilio. You will partner with other engineers and product managers to translate data needs into critical information that can be used to implement scalable data platforms and self service tools. We are looking for someone who is passionate about solving problems using engineering and data, thrives in an evolving environment, brings an enthusiastic and collaborative attitude, and delights in making a difference. As a successful candidate, you must have a deep background in data engineering and a proven record of solving data problems at scale leveraging distributed data systems. You are a self-starter, embody a growth demeanor, and can collaborate effectively across the entire Twilio organization.

Who?

Twilio is looking for an exceptional individual who lives Twilio Magic and has a proven track record in conceiving and delivering Data Warehouse solutions at company-wide scale.
8+ years of data engineering experience is a fast paced company that delivers software
Knowledge of all phases of software development including requirements analysis, design, coding, testing, debugging, implementation, and support.
A deep understanding of designing and building highly scalable Data warehouses and Data pipelines. Hands on Experience in PL SQL, Pyspark, Python, & Scala programming languages.
Deep understanding of Apache Spark, Spark tuning, creating RDDs and building data frames. Create Scala/Spark jobs for data transformation and aggregation.
Experience in building distributed environments using any of Kafka, Spark, Hive, Presto, Hadoop etc.
Deep understanding of architecture and functioning of Distributed database systems like Snowflake, Presto and Redshift (any).
Experience working with various file formats like Hudi, Parquet, Avro, ORC for large volumes of data
Experience with one or more NoSQL databases such as Cassandra, MongoDB, DynamoDB is a plus.
Solid understanding of engineering standard methodologies and design principles
Experience working in agile environment and iterative development
Collaborative approach and ability to work with distributed, multi-functional teams
Solid communication skills and the ability to clearly articulate your point of view
Bachelors/Master’s degree in Computer Science required, or equivalent experience
Should have superb communication and presentation, strong analytical and problem-solving skills
What?

As a Staff Data Engineer, you will live the Twilio Magic and:

Be an owner
Design and implement data management services for data trust, data compliance, data access and metadata management in the form of scalable and configurable while clearly articulating technical rationale behind your design and implementation choices
Participate in Agile/Scrum activities including planning, standups, retrospectives; Provide point of view on user stories.
Wear the customer’s shoes
Partner with data architects, product managers and other engineers to ensure they have the right information about our services and platforms while ensuring happy customers.
Listen to your customers’ challenges, find opportunities, craft solutions, and deliver the right value at the right time.
Write it down
Demonstrate excellent verbal and written communication - ensure that complex ideas, thoughts, and vision can be communicated simply and effectively. You are expected to thrive in a highly collaborative environment.
Draw the owl
You’ll build highly scalable platforms and services that support rapidly growing data needs in Twilio. There’s no instruction book, it’s yours to write. You’ll figure it out, ship it, and iterate. You’ll invent the future, but you won’t wing it.
Why?

The Enterprise Data and Business Intelligence is a central organization within Twilio that provides data infrastructure and related services in the form of data lake, data warehouse, business intelligence and data governance etc, that supports long term growth and sustainability. Our mission is to enable fact based decision making by providing clean, governed, accurate data in scalable and easy to use systems in a timely manner. We play an integral role in shaping our business decisions that enable company’s growth and success and are the backbone of Twilio’s data driven culture.

Twilio is a company that is empowering the world’s developers with modern communication in order to build better applications. Twilio is truly unique; we are a company committed to your growth, your learning, your development, and your entire employee experience. We only win when our employees succeed, and we're dedicated to helping you develop your strengths. We have a cultural foundation built on diversity, inclusion, and innovation, and we want you and your ideas to thrive at Twilio.

Where?

This position will be located in our office in Bengaluru, India. You will enjoy our office perks: catered meals, snacks, game room, ergonomic desks, massages, bi-weekly All Hands and more. What you will also get to experience is a company that believes in small teams for maximum impact; seeks well-rounded talent to ensure a full perspective on our customers’ experience, understands that this is a marathon, not a sprint; that continuously and purposefully builds an inclusive culture where everyone is able to do and be the best version of themselves.

About Us

Millions of developers around the world have used Twilio to unlock the magic of communications to improve any human experience. Twilio has democratized communications channels like voice, text, chat, video and email by virtualizing the world’s communications infrastructure through APIs that are simple enough for any developer to use, yet robust enough to power the world’s most demanding applications. By making communications a part of every software developer’s toolkit, Twilio is enabling innovators across every industry — from emerging leaders to the world’s largest organizations — to reinvent how companies engage with their customers."
38,"Job Description – Data Analyst

In Cisco, we have an outstanding opportunity where we actually get to use the technology we build!

We are Innovators

We drive innovation to propel business transformation while maintaining operational quality.

We are Accelerators

We accelerate digital solutions to generate cost savings and efficiency gains for enterprise growth and success.

We are Transformers

In Supply Chain Operations we have an opportunity and the responsibility to enable Cisco's business now and prepare for the future. Our vision and strategy continue to emphasize the importance of providing our customers an unrivaled customer experience by delivering a flexible, innovative and scalable supply chain while continuing to build upon our strong operational foundation. Cisco is also committed to social and environmental responsibility in our supply chain. We work with our suppliers to maintain a sustainable supply chain that meets our standards for ethics, labor practices, health and safety, and the environment.

We encourage you to become a part of this dynamic organization where on a daily basis we leverage Cisco's aggressive competitive spirit and accelerate time to market by empowering our employees to use their expertise to take good business risks. As Cisco expands into new technologies, and geographies, it's become an exciting time to be part of the Supply Chain Operations team.

Who You Are

Desired Degree Master's Degree (MS/MBA etc) Program

Desired Major Business, Industrial Engineering, Operations Research, Supply Chain Management or equivalent.

Minimum CGPA of 3.0 out of 4.0

The requirement is for 2022 passout only

Analyse business processes, find gaps and identify improvement opportunities

Strong Data analytics and visualization skills Work with large amount of data and having business context to derive meaningful insights from the analysis of the data

Present data and insights in a logical, influential manner to drive data driven business decisions

Capture the inventory of Supply Chain data sources, dashboards, measurements and metrics to prepare and manage integrated data architecture

Perform data mapping, lineage, classification and data dictionary to create Master Data Catalogue

Conduct Periodic data health monitor & cleansing

Assist with retiring unused data elements and rationalizing/enabling future data elements

Enable data discovery and various analytics platform with self-service model (predictive and prescriptive analytics

Partner with the functional owners on analysis of data flows, data stores, and measurements/metrics integration

Perform metrics analysis as required to provide actionable information to end users

Active participation in Data Scientist role & skills development across Supply Chain Operations.

Lead and drive Supply Chain cross functional teams to become analytics driven discipline

Why Cisco

At Cisco, each person brings their unique talents to work as a team and make a difference. Yes, our technology changes the way the world works, lives, plays and learns, but our edge comes from our people.

We connect everything – people, process, data and things – and we use those connections to change our world for the better.

We innovate everywhere - From launching a new era of networking that adapts, learns and protects, to building Cisco Services that accelerate businesses and business results. Our technology powers entertainment, retail, healthcare, education and more – from Smart Cities to your everyday devices.

We benefit everyone - We do all of this while striving for a culture that empowers every person to be the difference, at work and in our communities.

So, you have colorful hair? Don’t care. Tattoos? Show off your ink. Like polka dots? That’s cool. Pop culture enthusiast? Many of us are. Passion for technology and world changing? Be you, with us!

Disclaimer - “ Please note this posting is to advertise potential job opportunities. The requirement is for 2022 passout only. This exact role may not be open today, but could open in the near future. When you apply, a Cisco representative may contact you directly if a relevant position opens.”"
39,"Company Description

Epsilon is the leader in outcome-based marketing. We enable marketing that’s built on proof, not promises. Through Epsilon PeopleCloud, the marketing platform for personalizing consumer journeys with performance transparency, Epsilon helps marketers anticipate, activate and prove measurable business outcomes. Powered by CORE ID®, the most accurate and stable identity management platform representing 200+ million people, Epsilon’s award-winning data and technology is rooted in privacy by design and underpinned by powerful AI. With more than 50 years of experience in personalization and performance working with the world’s top brands, agencies and publishers, Epsilon is a trusted partner leading CRM, digital media, loyalty and email programs. Positioned at the core of Publicis Groupe, Epsilon is a global company with over 8,000 employees in over 40 offices around the world. For more information, visit epsilon.com. Follow us on Twitter at @EpsilonMktg.

Job Description

Who we are looking for

At Epsilon, we deliver excellence and create connections that last a lifetime. Our digital marketing arm, Conversant, is now growing and we are on the lookout for talented individuals who believe that every interaction counts - and want to make an impact on the future of our clients’ businesses.

So, are you someone who wants to work on the cutting edge of new-generation UI technology? Does the thought of working with Data, Machine Learning, and Artificial Intelligence excite you? Then you could be exactly who we’re looking for.

Apply today and be part of a dynamic, enthusiastic and passionate team who want nothing more but to make a lasting impact on the lives of consumers. You will also get the opportunity to see your ideas come to life on almost every consumer device across the US.

Role Description

We are looking for an Analyst to work with the larger Conversant Analytics Development teams across the globe. This role will help to build solutions for given product and analytics initiatives. Essential functions and responsibilities include: becoming familiar with digital and audience targeting practices; contributing to analytical code library using languages such as SQL, Python, R and SAS; and creating visualizations and dashboards to effectively communicate data-driven stories.

Qualifications
4+ years of industry experience with a degree in Statistics or related field
Tableau & Reporting – MUST HAVE skills
SQL knowledge
Knowledge of data warehouse principles (relational tables)
Experience with Business Intelligence products (Tableau) – Must Have
Good experience in working with geographically and culturally diverse teams
Excellent written and verbal communication skills.
Strong Analytical and problem solving skills
Ability identify and interpret trends or patterns in complex data sets.
Ability to diagnose and troubleshoot problems quickly
Additional Knowledge, Skills, And Abilities
Familiarity with the digital advertising industry (audience targeting, campaign optimization)
Knowledge of alternative programming languages (R, Python)
Familiarity with Agile process management"
40,"Job Title: Data Analyst

Location: Pune

About Barclays

Barclays is a British universal bank. We are diversified by business, by different types of customers and clients, and by geography. Our businesses include consumer banking and payments operations around the world, as well as a top-tier, full service, global corporate and investment bank, all of which are supported by our service company which provides technology, operations and functional services across the Group.

Risk and Control Objective

Ensure that all activities and duties are carried out in full compliance with regulatory requirements, Enterprise Wide Risk Management Framework and internal Barclays Policies and Policy Standards.

Working Flexibly

We’re committed to providing a supportive and inclusive culture and environment for you to work in. This environment recognises and supports ways to balance your personal needs, alongside the professional needs of our business. Providing the opportunity for all our employees, globally to work flexibly empowers each of us to work in a way that suits our lives as well as enabling us to better service our customers’ and clients’ needs. Whether you have family commitments or you’re a career, or whether you need study time or wish to pursue personal interests, our approach to working flexibly is designed to help you balance your life.

If you would like some flexibility then please discuss this with the hiring manager.

A brief description of the role.

Working with stakeholders to provide data insights for the pain areas identified.
Identify proactively areas where data insights can be used for business/ ops benefit.
Be a face to the stake holders for any requirement discussions.
Trouble shooting the technical problems.
Optimizing, automating processes using Machine Learning technique.
Translate findings into quantitative business/ops/monitory benefit for BANK.
Present the findings to stakeholders, highlight benefits and enhance the results based on feedbacks.

What will you be doing?

Solution Delivery
Build, test, and automate algorithms and processes.
Selecting features, building and optimizing using machine learning techniques.
Data mining using state of the art methods.
Documenting all work in accordance with agreed standards and with re-use in mind.
Conducting reviews of supplied specifications, with others as necessary.
Taking part in reviews of own work and leading reviews of colleagues’ work.
Taking responsibility for the analytics solution and documentation of particularly large, complex or mission critical programmes.
Clear understanding of enterprise level data model and mapping of data to it
Test Support
Assisting with the creation, review and sign off of test scenarios
Provide support throughout the testing cycles and also for production issues.
Provide right assistance for the testing cycles for delivery of error free deliverables
Accountable for producing detail design of components, conducting reviews.
Accountable for supporting E-2-E delivery during CIT/SIT/OAT and LIVE implementation
Coordinating with all the developers for the allocating the task and conducting code review and activities of implementation phase.
Responsibility for stabilising the best practices for design, development, implementation and automation.
Responsibility for prioritising live issues, problem records and delivering the fixes in IDS releases.
Data Analysis for new adopter’s alignment with IDS. Working on the scripts and work with RTB team.

What We’re Looking For

Experience in IT industry.
Proficient in Python, Teradata, Maria DB / SQL Server
Good Exposure in creating Data Model using ER Studio.
Proficient in Unix Shell Scripting
Good exposure to Oracle DB / SQL Server
Good exposure with Linux

Skills That Will Help You In The Role

Exposure to Analytical tool (Tableu) would be an added advantage

Where will you be working?

Pune

Be More at Barclays

At Barclays, each day is about being more – as a professional, and as a person. ‘Be More @ Barclays’ represents our core promise to all current and future employees. It’s the characteristic that we want to be associated with as an employer, and at the heart of every employee experience. We empower our colleagues to Be More Globally Connected, working on international projects that improve the way millions of customers handle their finances. Be More Inspired by working alongside the most talented people in the industry, and delivering imaginative new solutions that are redefining the future of finance. Be More Impactful by having the opportunity to work on cutting-edge projects, and Be More Valued for who you are.

Interested and want to know more about Barclays? Visit home.barclays/who-we-are/ for more details.

Our Values

Purpose and Values

We deploy finance responsibly to support people and businesses, acting with empathy and integrity, championing innovation and sustainability, for the common good and the long term.

Our values underpin everything we do: Respect, Integrity, Service, Excellence and Stewardship.

Respect

We harness the power of diversity and inclusion in our business, trust those we work with, and value everyone's contribution.

Integrity

We operate with honesty, transparency and fairness in all we do.

Service

We act with empathy and humility, putting the people and businesses we serve at the centre of what we do.

Excellence

We champion innovation, and use our energy, expertise and resources to make a positive difference.

Stewardship

We prize sustainability, and are passionate about leaving things better than we found them.

Our Diversity

We aim to foster a culture where individuals of all backgrounds feel confident in bringing their whole selves to work, feel included and their talents are nurtured, empowering them to contribute fully to our vision and goals.

Our Benefits

Our customers are unique. The same goes for our colleagues. That's why at Barclays we offer a range of benefits, allowing every colleague to choose the best options for their personal circumstances. These include a competitive salary and pension, health care and all the tools, technology and support to help you become the very best you can be. We are proud of our flexible working options for colleagues. If you have a need for flexibility, then please discuss this with us."
41,"At Hitachi Energy our purpose is advancing a sustainable energy future for all. We bring power to our homes, schools, hospitals and factories. Join us and work with fantastic people, while learning and developing yourself on projects that have a real impact to our communities and society. Bring your passion, bring your energy, and be part of a global team that appreciates a simple truth: Diversity + Collaboration = Great Innovation

The Hitachi Energy Indian Operations Center (INOPC) is a competence center with around 1500 skilled engineers who focus on tendering, engineering, planning, procurement, functional system testing, installation supervision and commissioning. However, over the last decade, it has evolved to become the largest engineering hub. The India Operations Centre is a key aspect of the Power Grids business Power Up transformation program. The INOPC team at Chennai supports Hitachi Energy’s units in more than 40 countries across a wide portfolio of all the four business units in Power Grid business. To date, the team has executed engineering and commissioning for projects in more than 80 countries.

Your Responsibilities
As a part of an International Engineering and Development Team heavily specialized in DT Transformers Engineering, Testing, Manufacturing and costing data analysis.
Display technical expertise in data analytics to a team of diversified technical competencies.
Propose project initiatives and value-added analytics that will drive business productivity.
Use data visualization tools such as Power BI and Tableau to create professional quality dashboards and reports.
Develop predictive models and utilize machine learning/data science techniques such as Hierarchical Clustering, Artificial Neural Networks, Ensemble Learning, Random Forest, Naive Bayes etc.
Consolidate SQL database from multiple sources, data cleaning and manipulation in preparation for analytics and machine learning.
Living core values of safety and integrity, which means taking responsibility for your own actions while caring for your colleagues and the business.

Your background
Bachelor’s in Computer Science, Data Science, or related discipline.
Minimum 2 (or more) years of related working experience.
Basic knowledge of SQL Server or a similar relational database.
Proficiency in Microsoft Power BI.
Machine Learning algorithm expertise is a valuable plus.
Experience of at least proven basic understanding of Distribution Transformers, or in general Power Distribution Industry related topics.
Experience in utilizing cloud-based environment for developing machine learning solutions such as Azure Machine Learning.
Proven record to learn new business background, engineering and manufacturing process quickly.
Display a proficiency in the creation and maintenance of data warehouse, business intelligence initiatives and asset diagnostic algorithms.
Experience with Python would be a plus.

More About Us

Hitachi Energy is a global technology leader that is advancing a sustainable energy future for all. We serve customers in the utility, industry and infrastructure sectors with innovative solutions and services across the value chain. Together with customers and partners, we pioneer technologies and enable the digital transformation required to accelerate the energy transition towards a carbon-neutral future. We are advancing the world’s energy system to become more sustainable, flexible and secure whilst balancing social, environmental and economic value. Hitachi Energy has a proven track record and unparalleled installed base in more than 140 countries. Headquartered in Switzerland, we employ around 38,000 people in 90 countries and generate business volumes of approximately $10 billion USD. www.hitachienergy.com

Transformers"
42,"Description

Job Location

Hyderabad (SAL) IN

Job Posting Title

Data Analyst

The Challenge

The Data Analyst will be responsible for setting up the Consumer Data Governance processes and Methodologies and implement Data Governance capabilities in Consumer area and help across other functions as required. The Data Governance is a strategic platform and a key enterprise initiative aimed at bringing better data ownership, Data Lifecycle management, Data Utilization, Data Quality and Metadata management across Functions in the Organization. This Data Analyst works with the Functional Owners, Business, SMEs and Enterprise Architects to implement one/more capability(ies) offered by the Data Governance Platform. He/She will be working technically in setting up integrations

What you will Do
Thorough understanding of all the capabilities offered by the Data Governance platform - Collaborate with Functional owners/team and Business partners to understand the use cases and problem statements - Clearly articulate/document the use cases and vet it out with Enterprise Architects - Discuss the solution approaches and merits/de-merits of each solution option - Participate and discuss in the CAB reviews to assess and understand the cross-functional impacts and questions/concerns from other teams/functions - Implement appropriate design / integration patterns to promote code re-usability - Employ strong coding standards for efficiency, readability, and reuse and participate in code review practices to ensure secure and good quality of the deliverables - Adhere to the overall Project management practices strictly following the project steps and uploading the required documents/resources at the designated repository (Sharepoint . .. ) - Exposure to Data Governance capability (lineages, workflows, Metadata management, Data Catalogs, Business Glossary Definitions etc. . .) - Proactively communicate the project status/progress/next steps/roadblocks (if any) - Complete the Data Governance capability implementation with clear definition of the achieved benefits and project documentation
What you need to Succeed
Bachelor of Engineering in Computer Science or equivalent from an accredited university or college - Hands-on experience on PL/SQL, Databases, Tableau, Informatica, Data Analysis - Good understanding of capabilities of Data Governance platform - Overall 5+ years IT experience and ~3 years of Data Governance/Strategy experience in any of the leading Data Governance platform - Highly collaborative and good team player - Highly proactive and results-oriented with excellent critical thinking skills - Good verbal and written communication skills
Exposure to data Lineages, metadata management, business glossary - Ability to identify and the use cases and map the DG capability to address it - Familiarity with Agile methodologies and ticketing systems like JIRA - Ability to work on multiple projects and tasks at the same time with proper prioritization
GE Appliances is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law."
43,"Job Summary

A role where the candidate will have regular interactions with various client team members for data management offered within the Deployment Solutions department of Syneos Health. The candidate will be the technical contact responsible for the management of account projects that include collecting, processing, analyzing, and loading of data and information regarding sales performance, operational effectiveness, and market position. Candidate should be comfortable working in an environment that is driven by process governance to ensure consistency and efficiency across client implementations and ongoing production control activities. Works closely with internal teams including Project Management, Incentive Compensation, Analytics & Reporting, and Client Services to determine project scope and data expectations to ensure the success of ongoing data exchange processes.

Job Responsibilities
Work independently to process information by loading / extraction of data.
Fulfill data task requests using Veeva data load tools.
Work independently to create ad-hoc extracts/reports and troubleshoot issues at the request of clients and sales management.
Perform quality control functions on all deliverables including standard deliverables, ad hoc loading and extraction projects.
Develop and maintain project documentation including work instructions for all repeatable tasks.
Provide feedback in design of new integration initiatives.
Meet with Sales Management and Clients to establish, monitor and review deliverables.
Other projects as deemed necessary by Management.
Education
Bachelor’s degree or Graduate degree, preferably in Computer Science, Technology or Engineering
Requirements
2-3 years of experience in working with data management teams within a sales and marketing environment
2-3 years of experience in data-centric implementations such as CRM and Analytics
2-3 years of experience with data warehouse, Master Data Management (MDM), and data integration initiatives
Strong SQL knowledge in an Oracle and/or SQL Server database environment
Strong organizational skills
Experience working in a production environment for multiple clients in a compliance industry
Preferred
Experience with Salesforce.com/Veeva or a similar CRM system a plus
Experience with Unix and/or Python scripting
Experience in Pharmaceutical and Life sciences implementations and awareness of commonly used data sources for Customer Master and Sales information
Primary Location

Asia Pacific - IND-Gurgaon-PresidencyTwrsMGrd

Other Locations

Asia Pacific - IND-Bangalore-Puram-Hobli-ETal

Job

Information Technology

Schedule

Full-time

Travel

No

Employee Status

Regular"
44,"You are still very ambitious and want something else? Are you looking for new energy in yourself? That’s great, especially if you have experience in data modelling & analysis. Take your career to the next level working with amazing people in GEA.

We are looking for a Sr. Data Analyst to support Procurement Excellence team. It’s about aligning procurement strategies and programs with the overall objectives of the company.

Responsibilities / Tasks

Procurement Excellence Projects in scope include (but are not limited to):
Prepare business cases for the Procurement Operating Model.
Support the development of category analytics reports and spend dashboards.
Assist category managers when they prepare and run negotiations.
Develop data model to monitor raw materials and their impact on GEA direct + indirect spend.
Develop a consolidated overview of ongoing customer projects in GEA.
Data cleanup in preparation for the deployment of a database.
Procurement Excellence Projects should be managed following basic agile principles:
Minimum Viable Products (MVP) defined early with a strong (internal) customer focus and business impact.
Short sprints with frequent follow-ups and deliveries to the business.
Procurement Excellence Data Analyst Is Expected To
Deliver on excellence projects within Global Procurement.
Maintain documentation of projects.
Monitor the progress (and escalate issues where appropriate).
The Excellence Team In India Is Used For

Procurement Excellence Data Analyst is part of a team based in India that supports the procurement Excellence team.
Assisting in data crunching, data modelling and data visualization.
Assisting in closing short/medium term projects for Procurement Excellence.
Analyzing, preparing and maintenance of data.
Creation of workflow, charts, reports and Dashboards.
Consolidating, categorization, cleaning and updating data.
Assists end users with troubleshooting technical issues, conducting queries and retrieving.
data from current business systems.
Coordination with Global supply chain, category manager, sourcing desk and Procurement excellence team throughout globe.
Your Profile / Qualifications

You hold bachelor’s degree or equivalent in engineering, industrial manufacturing, and management with having 2 to 5 years of experience.
Experience with advanced excel – excel formulas, charts, and pivot tables
Data modeling and how to extract, transform and load data.
Report, analysis & visualization of data.
Agile project management methods.
Professional knowledge on Power BI and Power Platform from Microsoft.
Driving analytics based on data across entities and cultures to support excellence projects within category management and procurement.
Database skills (SQL).
Python, R language.
Shows ability to plan, schedule, direct work of self and others.
Organizes materials to accomplish tasks; sets challenging yet achievable goals for self and others.
Solution seeker when faced with challenges.
Used to work systematically and independently with a team focus.
Excellent communication and collaboration skills.
Cross Culture Intelligence. Comfortable to work with multiple cultures around the world.
Good English skill – Verbal and written.
Did we spark your interest?

Then please click apply above to access our guided application process."
45,"Job Description

Role Summary/Purpose: The Data Analyst role will be responsible to conduct business analytics to generate insights to improve productivity, reduce quality defects and enhance customer experience by leveraging technology and analytical techniques or solutions. This includes projects related to customer analytics and segmentation, interaction and text analytics, quality assurance, automation, performance analysis, benefit estimations and reporting insights.

Essential Responsibilities
Utilize analytical solutions to develop usecases to support business opportunities and initiatives
Conduct industry research and explore advance analytics techniques including but not limited to text analytics, to identify opportunities in the business to improve customer experience, increase productivity and reduce expenses
Work independently with stakeholders to gather project requirements / inputs, develop analysis approach, execute analysis & present findings. Communicate business results/interpretations to stake holders and various partners to get their buy-in
Provide insights by leveraging cross-functional metrics from different functions
Generate innovative ideas and work on them which would have significant business impact
Proactively communicate status of projects to project owners and team members
Actively participating in team discussions and knowledge sharing forums
Communicate and engage across multiple levels in the business including senior leaders internally
Analytical and technical aptitude along with understanding business goals and correlating job to strategic initiatives
Proven track record of using sound judgment, decision making and problem solving
Perform ad-hoc data pulls and analysis as required
Excellent organization, prioritization, time management skills
Perform other duties and/or special projects as assigned
Motivate and inspire your team to be the best in the industry. As their leader, you will be their mentor, helping them navigate our culture and realize their career aspirations
Qualifications/Requirements
Bachelor's degree in Statistics, Mathematics, Operations research with 5+ year of overall experience
Minimum 2 years of experience with proven ability to extract unstructured and structured data with strong programming ability in SAS, SQL, R, Python or other programming languages.
Working knowledge of Microsoft Excel, PowerPoint, and Word
For Internal Applicants: Understand the criteria or mandatory skills required for the role, before applying.
Inform your Manager or HRM before applying for any role on Workday.
Ensure that your Professional Profile is updated (fields such as Education, Prior experience, Other skills) and it is mandatory to upload your updated resume (Word or PDF format)
Must not be any corrective action plan (First Formal/Final Formal, PIP)
Employees who have completed 18 months in the organization and 12 months in current role and level are only eligible.
Level 8+ employees can apply
Desired Characteristics
Good understanding of bank card, private-label, or financial services business
Experience on tools like click fox or any other equivalent tools are highly desirable
Data analysis using Python or R highly desirable
Hands on experience on Big Data environment
Grade/Level: 09

Job Family Group

Information Technology"
46,"To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.

Job Category Products and Technology Job Details

We are seeking an experienced Data Analyst to support the Employee Experience organization providing data analytics, reporting, responding to requests for data and in ensuring data integrity between multiple databases. The Voice of the Employee team’s mission, where this role sits, is to understand Salesforce Employee’s needs/goals in order to make actionable recommendations to elevate our employee’s experience. This critical role will deliver the business analysis, customer support and reporting necessary for the organization to reach its goals and objectives. You will work directly with Business Technology leadership, the entirety of the Voice of the Employee team, and with departmental stakeholders across the enterprise including those in the Employee Success and Finance. The scope of the role will also include analysis, reporting, and creation of executive level presentations for Employee Experience projects.

You will be working on a small team of highly motivated, curious, and impact driven individuals. We are obsessed with advocating on behalf of our employees and improving their daily experience to enable them to do their best work possible. The team values creativity, integrity, responsibility, communication, equality, and personal growth.

Responsibilities will increase as the employee demonstrates success in understanding processes, methodologies, and systems and shows initiative in tackling more complex projects.

Responsibilities
Consolidate and disseminate weekly (and potentially daily) updates of data from multiple systems and distill into leadership-level presentations illustrating trends and providing a comprehensive analysis
Analyze and evaluate data to be moved into our database
Ability to analyze multiple streams of data around employee experience and provide meaningful and actionable insights
Ensure that data is accurately flowing between different database systems and develop a repeatable process to ensure accuracy
Monitor data to ensure that key business stakeholders are kept current on registration trends
Build, maintain, update and optimize critical dashboards in Salesforce Supportforce orgs for key business stakeholders in Business Technology
Assist in developing executive-level presentations providing concise analyses of critical conference statistics
Assist in developing a framework for global events reporting standards including processes and refining critical metrics definitions
Provide analysis and develop executive briefings based on analyses
Assist, as requested, in extracting data and performing requisite analyses to answer critical business questions on tickets, trends, forecasting and other key variables as requested by business stakeholders
Assist, as requested, in providing updates and reporting on programs to customer-facing teams
Assist, as requested, in performing analysis to help guide business decision making. Understand trends in data and highlight this to management.
Assist, as requested, in providing support, analyses and insight for other high visibility Employee Experience projects
Ensure adherence to corporate data security requirements for the storage, transportation and retention of data
Required Skills/Experience
Solid 5+ years data analytics experience
Very strong Tableau and Excel skills. This is mission critical. Adept at integrating disparate information, building forecast, and trending models, developing comprehensive charts, working with pivot tables, analyzing large tables of data, comfortable using data analysis formulas, a strong aptitude for correlating data and finding critical data trends
Salesforce platform experience. Experience in building and creating reports and dashboards in Salesforce platform
Google Docs experience. Experience in Google slides and PowerPoint. Strong ability to distill data analysis, insight and other key findings into executive level PowerPoint briefings
Solid Experience using Business Objects and other Business Intelligence tools (ie Tableau)
Proficient in working in SQL
Track record of identifying business data needs, performing detailed and insightful analysis and developing reports that meet these needs and drive business results
Ability to provide analysis and insight based on partial information
Strong analytical and problem-solving skills
Must be able to work well in high trust team environment
Ability to understand the business and anticipate data needs
Must be comfortable with changing requirements and priorities and working in a fast-paced, high-pressure environment
Excellent verbal and written communication skills; ability to communicate effectively with different levels of management
Ability to work autonomously by proactively identifying opportunities to leverage skills and take initiative in working on solutions
Experience with data quality assessment and implementing solutions to improve the data quality is a plus
Experience designing and developing machine learning capabilities preferred
Desired Skills

Tableau and Anutics certification

Accommodations

If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form .

Posting Statement

At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at Salesforce and explore our benefits.

Salesforce.com and Salesforce.org are Equal Employment Opportunity and Affirmative Action Employers. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce.com and Salesforce.org do not accept unsolicited headhunter and agency resumes. Salesforce.com and Salesforce.org will not pay any third-party agency or company that does not have a signed agreement with Salesforce.com or Salesforce.org .

Salesforce welcomes all."
47,"We are looking for smart, driven Machine Learning Engineers who have the following skills & attributes:


Hard-skills

1. Python- including skill with pandas, scikit-learn and to a lesser extent Django or Flask


2. Good understanding of the machine learning algorithms


3. Experience working with hyper-paramter optimization, feature engineering, feature selection, calibration of models and benchmarking performance via AUC/Gini, Capture rates, K-S and other relevant metrics


4. Working knowledge of Linux


Soft-skills required

1. A keen sense of pride about work and the habit of taking ownership of work


2. Reliability & professional ethics"
48,"Data Science is all about breaking new ground to enable businesses to answer their most urgent questions. Pioneering massively parallel data-intensive analytic processing, our mission is to develop a whole new approach to generating meaning and value from petabyte-scale data sets and shape brand new methodologies, tools, statistical methods and models. What’s more, we are in collaboration with leading academics, industry experts and highly skilled engineers to equip our customers to generate sophisticated new insights from the biggest of big data.

Join us to do the best work of your career and make a profound social impact as a Analyst on our Data Quality Analytics team in Bangalore.

What You’ll Achieve

As a Data Quality Analyst, you will perform data governance tasks associated with the integration, cleaning, transformation and control of data in operational and analytics data systems. The DQA will create, document and maintain business processes and procedures and collaborate with team members to improve workflows and streamline processes.

You Will
Act as a cross-functional liaison across the following teams: Teradata/DDW EBI Teams, D3 application users, regional support teams and business groups.
Responsible for supporting Dell Data Warehouse, Dell Data Lake and D3/BOBJ users consuming finance, Sales and Manufacturing datasets
Determine root cause for data quality errors and make recommendations for long-term solutions
Work with business users to define and analyze problems and manage to resolution - provide technical details to IT team to deliver the fix and follow up with communication
Provide recommendations for measuring and improving the effectiveness and efficiency of data governance, operational control processes, and compliance activities
Provide Support on incidents raised via SNOW
Perform Financial Month/Quarter close Activities
Take the first step towards your dream career

Essential Requirements

Every Dell Technologies team member brings something unique to the table. Here’s what we are looking for with this role:
Data Warehouse knowledge/experience
Proficient in SQL with a minimum of 2-3 years of hands-on experience
Strong MS Excel skills and experience with reporting and data analysis
Ability to work with Technical and Non-Technical business owners
Flexible to changing priorities and to work on rotational shifts as and when needed.
High sense of urgency, strong attention to detail, excellent follow-up, ability to set own agenda & workload
Bachelor’s degree or Equivalent work experience
Desirable Requirements
Quickly adapt to new development environments and changing business requirements
Hands on Business Intelligence tools: SSIS, SSRS, Power BI/ Tableau Software
Here’s our story; now tell us yours

Dell Technologies helps organizations and individuals build a brighter digital tomorrow. Our company is made up of more than 150,000 people, located in over 180 locations around the world. We’re proud to be a diverse and inclusive team and have an endless passion for our mission to drive human progress.

What’s most important to us is that you are respected, feel like you can be yourself and have the opportunity to do the best work of your life -- while still having a life. We offer excellent benefits, bonus programs, flexible work arrangements, a variety of career development opportunities, employee resource groups, and much more.

We started with computers, but we didn’t stop there. We are helping customers move into the future with multi-cloud, AI and machine learning through the most innovative technology and services portfolio for the data era. Join us and become a part of what’s next in technology, starting today.

You can also learn more about us by reading our latest Diversity and Inclusion Report and our plan to make the world a better place by 2030 here.

Application closing date: 15 December 2021

Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment. All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate. Dell will not tolerate discrimination or harassment based on any of these characteristics. Dell encourages applicants of all ages. Read the full Equal Employment Opportunity Policy here.

Job Id: R151852"
49,"Job Description

1 Million ! That is the number of patients datasets you get to work with every day . We are looking for enthusiastic professionals who can Independently develop, modify and de-bug programming routines (such as SAS or R or python) along with complex SQL queries to extract, clean, manage, and analyze large databases. Must be familiar with one of the healthcare database like healthcare claims , Electronic Medical records , Registry . As a member of RWE team you will be conducting observational data analyses including data management and statistical programming as well as the development of RWE dashboards by translating the study design into complex algorithms in collaboration with RWE Research Analysts and colleagues or business partners across all Novartis franchises.]

Job Purpose

The Principal RWE Scientific Data Analyst will lead programming activities aligned with RWE strategies, including the programming of Real World Evidence (RWE) studies and dashboards.

Your key responsibilities:

Your responsibilities include, but are not limited to:
Lead projects in the development of programming routines (such as SAS or R) along with complex SQL queries to extract, clean, manage, and analyze large databases for health outcomes research. Data sources include medical and pharmacy claims data, hospital data, electronic medical record data, and prospective observational study data.
Provide guidance and translate the study design into algorithms to extract, analyze and report secondary data for Non-Interventional Studies (NIS) or interactive data visualization tools.
Collaborate with the RWE Research Analysts to scope and design projects.
Provide guidance in RWE tools such as R, R/shiny, SAS, Impala, git or JIRA
Conduct and provide guidance in observational data analyses including data management and statistical programming involving new creative approaches, as well as the design and development of RWE dashboards.
Provide guidance on machine learning and data mining techniques such as random forest, GBM, logistic regression, SVM, deep learning.
Substantial experience in dimensional reduction and R packages such as ggplot, plotly or t-sne.
Drive consistency and compliance with company standards regarding project documentation for observational studies and interactive data visualization tools, including programming, specifications of analysis datasets, tables, figures and listings.
Oversee and ensure compliance with company standards and processes.
Oversee the compliance and enhancement of standardization techniques in order to increase efficiency in deliverables.
Comply with project timelines together with the RWE Research Analysts and proactively alert the project manager or department leadership on any risks related to the deliverables and the timeline.
Interact and engage with the customers on a regular basis by providing regular updates on the project progress to ensure customer satisfaction.
Interact with stakeholders, Regional Account Directors (RAD) medical experts, and strategy directors.
Present results, project summaries, and analytical techniques to customers, stakeholders and internal audiences.
Mentor and upskill more junior members of the team.
Assist the department leadership in the hiring process of new talent.
Regularly elicit customers' satisfaction levels with Data Science's RWE services. Identify service areas requiring attention.
Encourage customer participation in the customer satisfaction survey.
Manage the outsourcing of programming activities from Data Science to an approved vendor in accordance with Novartis vendor management procedures.


Commitment to Diversity & Inclusion:

Novartis is committed to building an outstanding, inclusive work environment and diverse teams representative of the patients and communities we serve.

Minimum Requirements

Bachelor’s degree plus 8+ years as programmer or data scientist in the pharma industry, contract research organization, or academic institute; or experience in a closely related discipline.

Or

Master’s degree in a field such as computer science, bioinformatics, biostatistics, statistics or similar. And 5+ years of experience as programmer or data scientist in the pharma industry, contract research organization, or academic institute; or experience in a closely related discipline.

Or

PhD in a field such as computer science, bioinformatics, biostatistics, statistics or similar. And 4+ years of experience as programmer or data scientist in the pharma industry, contract research organization, or academic institute; or experience in a closely related discipline.
Expert in the following R packages: Shiny, Rmarkdown, ggplot, plotly, data.table, dplyr.
Expert in version control tools such as git or JIRA.
Expert in setting up standardized programming scripts.
6+ years of programming experience and proven technical abilities with data manipulation, analysis and visualization including SAS or R, SQL and other statistical software.
An interest in developing programming, statistical, visualization and analytical skills.
Prior experience using large transactional databases such as claims databases, EMR, registries or financial databases.
Exceptional problem-solving abilities with solid experience of statistical methods and machine learning.
Solid experience in SQL querying using at least one of the following Hive, Impala, MySQL, OracleSQL or similar.
Understanding of organizational processes, including experience working cross-functionally with key internal stakeholders.
Solid experience with big data platforms such as Hadoop, Apache Spark.
Confident and competent when interacting with internal stakeholders.
Excellent project management skills: can prioritize multiple tasks and goals to ensure timely completion.
Strong written/verbal communication skills. Highly effective at providing input at meetings, discussions and activities covering aspects of research data management and analysis on research projects.
A strong interest in working in pharma.
Open to experimentation and taking smart risks to support creative thinking that leads to practical solutions to healthcare and business challenges.
Holds a high standard on quality excellence. Continuously seeking to enhancing standards, technology through expansion of knowledge and training.
Support teamwork to swiftly and efficiently deliver innovative new products to patients and healthcare providers.
High ethical values and standards.
Able to speak out, challenge conventional thinking, and stand up for ideas.
Strong team spirit.
Ability to work well within a global organization.


769 million lives were touched by Novartis medicines in 2020, and while we’re proud of this, we know there is so much more we could do to help improve and extend people’s lives.

We believe new insights, perspectives and ground-breaking solutions can be found at the intersection of medical science and digital innovation. That a diverse, equitable and inclusive environment inspires new ways of working.

We believe our potential can thrive and grow in an unbossed culture underpinned by integrity, curiosity and flexibility. And we can reinvent what's possible, when we collaborate with courage to aggressively and ambitiously tackle the world’s toughest medical challenges. Because the greatest risk in life, is the risk of never trying!

Imagine what you could do here at Novartis!

Commitment to Diversity & Inclusion:

Novartis is committed to building an outstanding, inclusive work environment and diverse team’s representative of the patients and communities we serve.

Division

CTS

Business Unit

NBS CONEXTS

Country

India

Work Location

Hyderabad, AP

Company/Legal Entity

Nov Hltcr Shared Services Ind

Functional Area

Data Science

Job Type

Full Time

Employment Type

Regular

Shift Work

No

Early Talent

No"
50,"Job Title: Principal BT Data Analyst

Job Summary

The primary purpose of this role is to execute and coordinate technical activities/deliverables between both on-shore and offshore development teams, clients, external vendors and service providers. This is a customer-facing role with regular interactions with various client team members for data management services offered within the Sales Operations. The candidate will work closely with internal teams including Project Management, Quality Assurance, IC, Business Intelligence and Compliance to determine project scope, work effort and expectations to ensure the success of ongoing data exchange processes.

Key Job Responsibilities

(Duties may include, but not limited to all or some of the following)
Engage with clients/external providers to facilitate data services related project delivery schedule
Plans, deploys and monitors to deliver on new requests
Lead and guide ongoing data exchanges
Enforce Data Management standards across all client implementations
Manage resources to ensure knowledge, exposure, and contribution are optimized
Job Qualifications

Education
Bachelor’s degree or Graduate degree, preferably in Computer Science, Technology or Engineering
Requirements
Experience in Pharmaceutical and Life sciences implementations and awareness of commonly used data sources for Customer Master and Sales information
5+ years of experience in working with data management teams within a sales and marketing environment
5+ years of experience with data warehouse, MDM and data integration initiatives
Strong SQL knowledge.
Experience with Unix and/or Python scripting
Experience working in a production environment for multiple clients in a compliance industry
Experience with Salesforce.com/Veeva or a similar CRM system a plus
Skills
Ability to lead a team through the implementation and adoption of data exchange services
Resource Management including scheduling, tracking, and estimating work effort
Good communication skills, both verbal and written
Conflict resolution
Detail oriented and analytical with planning and organizational skills
Excellent interpersonal skills
Strong initiative and a self-starter
Specific knowledge of client business and technology/data operations in the Pharmaceutical industry.
Skill in troubleshooting and problem solving.
Requirements
Experience in Pharmaceutical and Life sciences implementations and awareness of commonly used data sources for Customer Master and Sales information
5+ years of experience in working with data management teams within a sales and marketing environment
5+ years of experience with data warehouse, MDM and data integration initiatives
Strong SQL knowledge.
Experience with Unix and/or Python scripting
Experience working in a production environment for multiple clients in a compliance industry
Experience with Salesforce.com/Veeva or a similar CRM system a plus
Primary Location

Asia Pacific - IND-Home-Based

Job

Information Technology

Schedule

Full-time

Travel

No

Employee Status

Regular"
51,"Job Description:We are looking for Sr Consultant,Tech who will be responsible for bridging the gap between IT and the business using data analytics to assess processes, determine requirements and deliver data-driven recommendations and reports to stakeholders.

In this role, prefer to have a background in data and business analysis related to payor-provider healthcareecosystem, HIS, Electronic Medical Report (EMR, Claims management, Revenue cycle management.Good knowledge on FHIR, ICDs and other coding standards (ICD10, CPT, LOINC, HCPCS, SNOMED). You should be analytical and an excellent communicator. If you also have a business acumen and problem-solving aptitude, wed like to meet you.

The person will engage with business leaders and users to understand how data-driven changes to process, products, services, software and hardware can improve efficiencies and add value. They must articulate those ideas but also balance them against whats technologically feasible and financially and functionally reasonable. Depending on the role, you might work with data sets to improve products, services or process.

Duties and Responsibilities -

Develop support the designing and building multi - tenanted modern data warehouses, predictive and prescriptive analytics, and visualization platform.

Understands technical, business, and organizational requirements of a modern data warehouse and business intelligence platform.

Proven experience architecting scalable, performance - oriented solutions using emerging Big Data technologies and traditional ETL tools.

Leads and owns evaluation and selection of technology products to meet strategic business intelligence data management objectives.

Lead discussions with stakeholders on software requirements and design aspects related to key technical components,frameworks, interfaces etc.

Mentor / coach junior developers and leads in the team(s) during design review, implementation and use of best practices and guidelines.

Building E2E ML pipelines: Data prep, Model Build, training models, Deployment for AI/ML.

Basic Qualifications

Graduate/P.G in Computer Science, Engineering or relevant field with 10+ yrs of exp, preferred in Healthcare domain.

At least 5+ years of experience in developing solutions using Big Data technologies.

Hands on experience on the Hadoop distribution along with Kafka, Spark, Impala, Pig, Hive, Sqoop, Oozie etc. RDBMS Nosql DB.

Good understanding of relational DBs (MySQL / Oracle), Columnar DBs, ETL / ELT tools (Informatica Power Center / Scoop/Spark).

Understanding of both Data Engineering and Data Science aspects.

Designing machine learning systems and self-running artificial intelligence (AI) software to automate predictive models.

Transforming data science prototypes and applying appropriate ML algorithms and tools.

Developing ML algorithms to analyze huge volumes of historical data to make predictions.

proficiency with Python, Java, and R code writing.

Extensive knowledge of ML frameworks, libraries, data structures, data modeling, and software architecture.

Good knowledge of mathematics, statistics, and algorithms.

Experience building E2E ML pipelines: Data prep, Model Build, training models, Deployment, Scoring, Monitoring, and Optimization.

Proficiency with Python and basic libraries for machine learning such as scikit-learn and pandas

Strong knowledge of Unix/Linux, shell scripting.

Must exhibit a high degree of motivation, creativity, and initiative

Excellent analytical and problem-solving skills.

Strong desire to drive continuous improvement.

Work as Individual contributor with hands on experience to contribute as a Technology Domain SME.

This job is provided by Shine.com
Desired Skills and Experience
reporting, ""data analysis"", ""big data"", sql, ""data modeling"", ""microsoft excel"", ""data engineering"", ""data science"""
52,"Overview

The supervisor will support Client Account Services activities for in-flight documentation remediation projects. The analyst will work across several products and remediation projects (i.e. regulatory requirements and control/risk related issues).

The role will involve working with client agreements and related documentation. The responsibilities will include leading a team performing functions across searching, scanning, indexing legal documents to an electronic imaging systems and maintaining client records. The manager will be required to review documents to ensure they satisfactorily meet specific outlined requirements. Additionally, the manager will be expected to contribute to a wider team, provide regular progress updates, maintain an understanding of client documents, approach their work with a control-mindset, and demonstrate an understanding/application of policies and procedures.

Qualifications
Strong verbal and written communication skills
Good team player and self-motivated
Strong analytical skills
Desire to work in a fast-paced environment with multiple deliverables
Proven skills in time management, organization, and attention to detail
Proficiency in Microsoft Office suite of applications
Preferred experienced with client documentation and JPM systems
JPMorgan Chase & Co., one of the oldest financial institutions, offers innovative financial solutions to millions of consumers, small businesses and many of the world's most prominent corporate, institutional and government clients under the J.P. Morgan and Chase brands. Our history spans over 200 years and today we are a leader in investment banking, consumer and small business banking, commercial banking, financial transaction processing and asset management.

We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants' and employees' religious practices and beliefs, as well as any mental health or physical disability needs.
"
53,"Sr BT Data Analyst

Come discover what our 25,000+ employees already know: work here matters everywhere. We’re a growing and evolving biopharmaceutical industry leader, which means you’ll have endless opportunities to work with experts around the world and build the career you’ve dreamed of.

As a part of the Syneos Health team, you’ll help us deliver results for a rewarding reason – we improve patients’ lives around the world. Because to us, a patient isn’t just a number, they’re our family, friends, and neighbors.

Why Syneos Health
#SyneosHealthLife means we’re committed to our Total Self culture – where everyone can authentically be themselves. Our Total Self culture is what unites us globally, and we know every person’s unique contributions make a difference.
We believe our success is a direct result of the people who are driving it – you! We value your dedication to care for our customers and patients, so we want to focus on taking care of you. That’s why we offer a comprehensive benefits program encompassing your total health - physical, mental and financial.
We are continuously building the company we all want to work for and our customers want to work with. Why? Because when we bring together diversity of thoughts, backgrounds, cultures, and perspectives – we’re able to create a place where everyone feels like they belong.
Job Summary

A role where the candidate will have regular interactions with various client team members for data management offered within the Deployment Solutions department of Syneos Health. The candidate will be the technical contact responsible for the management of account projects that include collecting, processing, analyzing, and loading of data and information regarding sales performance, operational effectiveness, and market position. Candidate should be comfortable working in an environment that is driven by process governance to ensure consistency and efficiency across client implementations and ongoing production control activities. Works closely with internal teams including Project Management, Incentive Compensation, Analytics & Reporting, and Client Services to determine project scope and data expectations to ensure the success of ongoing data exchange processes.

Job Responsibilities
Work independently to process information by loading / extraction of data.
Fulfill data task requests using Veeva data load tools.
Work independently to create ad-hoc extracts/reports and troubleshoot issues at the request of clients and sales management.
Perform quality control functions on all deliverables including standard deliverables, ad hoc loading and extraction projects.
Develop and maintain project documentation including work instructions for all repeatable tasks.
Provide feedback in design of new integration initiatives.
Meet with Sales Management and Clients to establish, monitor and review deliverables.
Other projects as deemed necessary by Management.
Education
Bachelor’s degree or Graduate degree, preferably in Computer Science, Technology or Engineering
Requirements
3+ years of experience in working with data management teams within a sales and marketing environment
3+ years of experience in data-centric implementations such as CRM and Analytics
3+ years of experience with data warehouse, Master Data Management (MDM), and data integration initiatives
Strong SQL knowledge in an Oracle and/or SQL Server database environment
Strong organizational skills
Experience working in a production environment for multiple clients in a compliance industry
Preferred
Experience with Salesforce.com/Veeva or a similar CRM system a plus
Experience with Unix and/or Python scripting
Experience in Pharmaceutical and Life sciences implementations and awareness of commonly used data sources for Customer Master and Sales information
Experience with Apache Spark
Primary Location

Asia Pacific - IND-Gurgaon-PresidencyTwrsMGrd

Other Locations

Asia Pacific - IND-Hyderabad-DLF-Cybercity

Job

Information Technology

Schedule

Full-time

Travel

No

Employee Status

Regular"
54,"Description

The Sr Data Analyst writes programs, as well as maintains and modifies existing applications programs. He/she must also document and execute test plans according to the requirement and can be assigned to support.

She/He is also responsible for creating solutions for issues identified in the course of testing and following the Ingram Micro chosen applications development standards and methodologies.

Works primarily on an independent basis within the guidelines given for delivery of technical work assignments. He/she must have great communication and collaboration skills and must be team oriented. He/she must be able to clearly provide detail on their progress on tasks and must be able to raise issues that would impact the delivery in a timely manner.

Shifts are between 12 Noon - 9 PM with weekends as off-days although members can be asked to report to work at night and/or during weekends and/or holidays.

Build/Development & Production Support

Supporting Actions
Can analyze the design/issue and translate the design into code
Can create detailed test plans that cover the critical scenarios that must be unit tested for the requirement/ticket
Escalates issues or gaps in the design/resolution approach
Able to set expectations with Users/DM and secure UAT approval.
Communicates with on-shore for approvals
Can investigate and determine the root cause of the issue.
Unit Testing
Can document and execute detailed test plans for unit testing
Can do bug fixing on builds he/she performed.
IST/UAT
Can establish communication with users/DM to understand the issue.
Can provide a fix to the issues encountered during testing that is related to the requirement
Can do bug fixing on builds he/she performed
Technical Skills
Overall 5-7 years of experience
Should have good experience with Data Warehousing and modeling
Strong knowledge in Java , Unix, Python
Strong background in RDBMS such as MSSQL or Oracle or Sybase
Knowledge of Data Lake Technologies and Modernization; Big Data, AWS, SPARK
Experience working in Informatica, Power BI is a plus
Domain knowledge in Logistics and Supply Chain is a Plus.
¨ Good communication skills both written and verbal."
55,"Be part of something revolutionary


We have a vision. Our Digital Brain, o9’s AI-powered platform, is being used by global enterprises to drive their digital transformations. The integrated planning and operational efficiencies we provide is helping businesses do more, be more and mean more to the world at large. Because businesses that plan better, reduce waste, creating value for themselves and the planet.


But we also have a vision for our people. We want the most talented, committed and driven people to power our transformative approach. In return, we’ll provide a nurturing environment where you can be a part of something special.


About the role...


Our Backend Dev Team is a part of a highly motivated and goal oriented product to develop high quality software components and modules for use in enterprise applications.


What you’ll do for us…


Design and implement algorithms and functions to solve a range of problems in the supply chain planning and demand forecasting space. The following are some of the problems that be involved:
Develop an optimal material allocator module for creating purchase orders.
Develop a heuristic to build optimal loads to minimize the number of trucks needed to ship a set of sales orders for materials.
Develop modules to call web services for real time integration with external systems
Develop algorithms to recognize patterns in large datasets.
These software components will be deployed as part of the standard product or in custom implementations for specific customers using programming languages R and Python
What you’ll have…


Experience: Experience in R / Python. Willingness to work in multiple languages like C#, javascripts.
Experience/good knowledge of optimization methods such as linear programming, numerical optimization a huge plus.
Hands-on experience in data structures and algorithms

Education: Bachelor's degree or above in computer science, or similar.
Skills: Strong programming skills and experience in writing performance-optimized code working over very large datasets.

Characteristics: Extremely strong analytical skills.
We really value team spirit: Transparency and frequent communication is key. At o9, this is not limited by hierarchy, distance, or function

What we’ll do for you…

Get social: When we work from home, we play from home with fun after-work activities like Friday Socials. If you’re in the office, feel free to join these events in person.
Flat organization: With a very strong entrepreneurial culture (and no corporate politics).
Great people and unlimited fun at work.
Possibility to really make a difference in a scale-up environment.
Support network: Work with a team you can learn from and every day.
Diversity: We pride ourselves on our international working environment.
o9 is an equal opportunity employer and seeks applicants of diverse backgrounds and hires without regard to race, colour, gender, religion, national origin, citizenship, age, sexual orientation or any other characteristic protected by law.
How the process works...


Apply by clicking the button below.
You’ll be contacted by our recruiter, who’ll fill you in on all things o9, give you some background about the role and get to know you. They’ll contact you either via video call or phone call - whatever you prefer.
During the interview phase, you will meet with our technical team for 1 - 1.5 hours each(2/ 3 rounds). The recruiter will contact you after the interview to let you know if we’d like to progress your application.
We’ll then invite you to complete a written assignment via email.
Your application has progressed! Meet with our Hiring and HR Manager for a final round of interviews for 60 minutes, respectively.
Our recruiter will let you know if you’re the successful candidate.
Good luck!


More about us…


With its recent Unicorn status, o9 Solutions is one of the fastest growing AI-powered digital transformation companies in the world today. Our high energy environment drives us to grow and aim 10x. It’s this drive that has made us leaders of Gartner’s S&OP Magic Quadrant.


The o9 platform, or “digital brain”, is the premier AI-powered, cloud-based platform behind the digital transformations of major global enterprises. These include Google, Walmart, and Starbucks, among others.


Our headquarters are located in Dallas, and we currently have offices in Amsterdam, Barcelona, Bangalore, Tokyo, Seoul, Paris and London.


o9 is an equal opportunity employer. We welcome applicants of diverse backgrounds and hires without regard to race, colour, gender, religion, national origin, citizenship, age, sexual orientation or any other characteristic protected by law."
56,"The ideal candidate is a highly resourceful and innovative developer with extensive experience in the layout, design and coding of websites specifically in PHP format. You must also possess a strong knowledge of web application development using PHP programming language and MySQL Server databases.

Responsibilities

Perform a mix of maintenance, enhancements, and new development as required
Work in a data analyst role and with business intelligence applications
Document features, technical specifications & infrastructure Responsibilities
Work cross-functionally to convert business needs into technical specifications

Qualifications

1+ years' of experience in web development and software design
Expertise in front-end technologies (HTML, JavaScript, CSS), PHP frameworks, and MySQL databases"
57,"The ideal candidate will be responsible for creating python microservices.


Job Description

Design, develop, troubleshoot, and debug python microservices.
Work closely with Architects and Senior Developers to achieve effective and optimized code.
Unit test, build, and deploy the services to cloud.
Focus on developing and deploying the programs.

Job Requirements

Min. 1 to 2 years of related experience
Having dominant skills in: Python, Web Development
Having essential skills in: Python Django, HTML, CSS, Javascript, Jquery, Bootstrap
Strong analytical skills
Strong communication skills including the ability to convey technical information effectively
Having good perfomance in completing the tasks within an agreed schedule

About EIS LABS Pvt. Ltd. ®

EIS LABS Pvt. Ltd. ® is a tangible manifestation of the lofty ideals of some visionaries, who are well known experts in their respective fields of work. We had always nurtured a dream & desire to make a significant contribution to the nation through collaboration of education with industry. Our dream and desire inspired us to establish a platform, EIS LABS Pvt. Ltd. ®. The vision for the company is to bring the academic researches on a single platform and mold them into industrial products with the help of our expertise."
58,"The ideal candidate will be responsible for developing high-quality applications. They will also be responsible for designing and implementing testable and scalable code.

Responsibilities

Develop quality software and web applications
Analyze and maintain existing software applications
Design highly scalable, testable code
Discover and fix programming bugs


Qualifications

Bachelor's degree or equivalent experience in Computer Science or related field
Development experience with programming languages
SQL database or relational database skills"
59,"Note(please read these information before applying):

Please share resume and below details in one email with subject line “Python Dev” to get your application processed immediately.
Candidate who haven't registered in iBegin (TCS) career portal will get link for registration so they need to complete basic registration. Candidate who are already registered will be processed with same EP number.
Below details are required for eligibility check before processing application for interview.
Candidates with less than 3 years of experience will not be considered.

Method to Apply:

Share updated CV with below required details at zainab.moulvi@tcs.com


If already registered in iBegin portal then please share either EP number or Registered email id:
Full Name(only First & Last name):
Email ID:
Contact number:
Total experience:
Current Payroll company:
Current location:
Preferred Work Location (Open to relocate to Bangalore, Hyderabad or Bhubaneshwar?) :
Notice period( Please specify LWD if serving notice):
CTC:
Expected CTC:
Offers in hand(with salary details):
Education Gap(only duration):
Employment Gap(only duration):
Highest Fulltime education:
University/institute name of Highest education:
Have you worked in TCS or any subsidiary of TATA before?:

Desired Competencies :

Must have 5+ years of as python developer.
Hands on experience with Django, Flask or other Python frameworks
Good understanding of server-side templating languages such as Jinja 2, Mako, etc
Basic understanding of front-end technologies, such as JavaScript, HTML5 and CSS3
Familiarity with some ORM (Object Relational Mapper) libraries

Good to have :

1. Excellent interpersonal, organizational, written communication, oral communication and listening skills

2. Should come up with the work estimation and should provide inputs to managers on resource and risk planning.

3. Ability to coordinate with SMEs , stakeholders, manage timelines, escalation & provide on time status


Qualifications :

5+ yrs of overall experience.

Job Location

Bangalore
Hyderabad
Bhubaneshwar"
60,"Responsibilities:

- Write effective and scalable code

- Development of Core APIs

- Develop back-end components to improve responsiveness and overall performance

- Integrate user-facing elements into applications

- Test and debug programs

- Implement security and data protection

- Assess and prioritize feature requests

- Attend the daily scrum call

- Coordinate with the management team, front-end developer

- Participate actively in brainstorming sessions


Requirement:

- Experience with developing APIs

- Experience of working with flask framework or Django framework

- Knowledge of object-relational mapping (ORM)

- Familiarity with front-end technologies (like JavaScript and HTML5)

- Good problem-solving skills


Experience: 2 to 3 years experience


Duration: Immediate requirements"
61,"Python SSE1


We are looking for a python expert who can design, develop and deploy performance efficient programs. He must be a problem solver with positive attitude.


Responsibilities:

1. Requirement understanding and analysis

2. Architectural design

3. Development

4. Guiding sub-ordinates

5. Client communication

6. Design, drive and develop solutions.

7. Enhance, guide and fix ongoing projects.


Skills:

Must to have:

1. Object Oriented Programming

2. Strong knowledge of algorithms, data structures, multi-threading and time complexities

3. Strong knowledge of Python Language

4. Well versed with framework like Django, Flask, Pyramid or similar platform etc.

5. Experience on development of scalable and performance efficient restful APIs, Bot Scripts, Crone Jobs etc.

6. Object Relational Mapping

7. Familiar with Angular, React etc

8. SQL and NoSQL databases

9. Secure Architecture and Best Practices


Good to have:

1. Tensorflow

2. Exposure to IoT

3. Exposure to Blockchain and Cryptography

4. TDD

5. Version Control System like Git

6. AWS and/or Azure

7. Agile methodology

8. CI/CD

9. Docker

10. Third party API integration

11. Involvement in open source projects


Behavioral Skills:

1. Must be a self motivated problem solver and strong team player

2. Out of the box thinker

3. Quick learner

4. Good communication skills


Qualification:

If you feel you are the best suited one for above requirement then education is not a barrier, we welcome any graduates and dropouts as well.


Experience: 3-5 Years of hands on experience on pure python development."
62,"Experience: 1 to 2years

Location: Ahmedabad

(Only Gujarat Based Candidates are preferred)


Company description: We are a software development company who has customers across US, Spain and South Africa. We are into software development with niche of services with Web and Mobile development projects. We have niche in providing python development services. we enable our global customers achieve digital transformation and provide smart product solutions with our tech consulting, bespoke solutions, as well as professional services. We enable clients across the globe to navigate their digital journey with integrated technology models, business intelligence, and next-gen tech expertise to catalyze change.

Job Description


Expert in Python, with knowledge of Python web framework Django
Able to integrate multiple data sources and databases like Postgres, MySQL, mongodb, elasticsearch, cloud datastore, dynamodb.
Understanding of the threading limitations of Python, and multi-process, micro service architecture
Good understanding of server-side templating languages like Jinja 2
Basic understanding of front-end technologies, such as Angular, React, JavaScript, HTML5, and CSS3
Understanding of accessibility and security compliance depending on the specific project
Knowledge of user authentication and authorization between multiple systems, servers, and environments
Understanding of fundamental design principles behind a scalable application
Familiarity with event-driven programming in Python
Understanding of the differences between multiple delivery platforms, such as mobile vs desktop, and optimizing output to match the specific platform
Understanding of cloud platform services like Google Cloud, AWS with dockerized systems.
Able to create database schemas that represent and support business processes
Strong unit test and debugging skills
Proficient understanding of code versioning tools such as Git.

PERSONALITY TRAITS WE REALLY ADMIRE

Excellent Communication and Client Coordination Skill
Great attitude to ask questions, learn and suggest process improvements.
Pays great attention to detail and helps identify edge cases.
Gives equal importance to planning, coding, code reviews, documentation, and testing.
Highly motivated and coming up with fresh ideas and perspectives to help us move towards our goals faster.
Follows release cycles and absolute commitment to deadlines.

Education Qualifications

BE(Computers/IT), ME(Computers/IT), MCA, MSC IT, BCA, Any IT Graduates
"
63,"Workfall is looking for a Python/Django Developer who can work with one of our product development teams.


Mandatory Requirement: Between 2 to 5 years of Python coding experience using the Django framework. Experience of working on Open edX framework will be an added advantage.


Work Location: Remote


What you will be doing:

Building a feature-rich, Django-based product in a very popular business domain.
Specifically, you will be:
Developing REST APIs, building service-oriented architectures, and working in an agile development environment.
Crunching down Data Structures and Algorithms
Deploying scalable applications to the AWS Cloud.
Working extensively on Git
Working closely with the front-end team so basic knowledge of front-end (CSS, HTML, Javascript, and Angular) will help.
Using MySQL/Postgres, MongoDB, Redis
Solving complex problems with analytical thinking
Taking responsibilities of designing, customizing, developing, deploying, and managing the product.

What we care about:

Your attitude and work ethic.
Your willingness to learn new things.
Your commitment to your own professional growth.

What we don’t care about:

Your school/college degree.
Your age.
Your gender.
Your location."
64,"Unique job opportunity!


a Russian startup is looking for a Junior Developer to join their team. 100% remote work. It is not necessary to have work experience.


In case the person adheres to our principles, in the future we offer possible relocation to Moscow-Russia, as well as we will teach you the Russian language.


The candidate must have the following requirements:


Be a professional or student in the last semesters of systems/electronics engineering, or related fields.
Have a good level of English (B1 at least) and be willing to excel it (in case you don't have this point, but still feel like applying, do it)
You should have an analytical mindset

It will be an advantage if you know any of these technologies:

Javascript ES5 / ES6, VueJS, Ionic, Nodejs, Nuxtjs


You're the perfect candidate if:

You want to learn and grow professionally, you know that to be successful in life you have to strive, you want to be part of something unique in your life, you want to be successful.
You are willing to learn and want to be the best at what you do.
You are searching for a long-term position, as far as we are building a strong team to make worldwide projects. We do not want to hire someone who will go from us after some months.


Important! This is not an opening to earn a lot of money, so for people who have high salary expectations it is better that they do not apply, we are looking for someone who is willing to grow with us.


The salary is discussed with the applicant, depending on their profile. To those interested, apply and indicate your salary expectation in USD dollars and we also request, a small text where you explain in your own words, what do you think would be the reason why we would choose you and not another candidate?


**Applicants which do not send their salary expectations will not be considered in the selection process."
65,"INTRO

One develops B2B SaaS Software that helps small businesses, freelancers and consultants grow by increasing revenues while reducing effort. One brings in more clients, streamlines client engagement, generates invoices and tracks payments. We are 100% remote and looking for the best to join Team One!


ROLE

As CTO & Co-founder, you will work closely with the founder(s) in realizing the company's vision of making small businesses more successful. You will be responsible for architecting, developing and scaling a web app with customers around the world. You will also be responsible for building a team that can consistently deliver high quality software that delights our customers.


EXPERTISE


Technology skills:

Architecting, building and scaling complex web apps
Hosting on cloud platforms: GCP / AWS / Azure
Typed language like Java, preferably Typescript
Application development using Node.js / Python / Ruby
Building highly scalable apps using any RDBMS and NoSQL DB
Caching tools like Redis / Memcached
Messaging broker or Queuing services: Kafka / AWS SQS / RabbitMQ
Modern frontend frameworks: React.js / Angular.js / Vue.js
HTML, CSS, Javascript and web APIs
SSR apps, PWA, intelligent push notifications & analytics tools
Hybrid mobile apps that complement our web apps

People skills:

Build a team that enjoys working on all of the above
Estimate and deliver complex web projects on time
Interact with customers to evolve our technology and product strategy
Interact occasionally with media, partners and investors
Build a great partnership with the founding member(s) of the team

Summing up, if you are a fast learner, passionate about your craft and our vision, we would love to hear from you!"
